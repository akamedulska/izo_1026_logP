[
  {
    "objectID": "model_1.html",
    "href": "model_1.html",
    "title": "",
    "section": "",
    "text": "CodeShow All CodeHide All CodeView Source"
  },
  {
    "objectID": "model_1.html#priors",
    "href": "model_1.html#priors",
    "title": "",
    "section": "Priors",
    "text": "Priors\nDue to the appearance of new parameters, prior distributions were reviewed. The clustering of analytes seems to be caused by the presence of analytes in a neutral or dissociated form at the pH of the mobile phase used in this set of experiments.\n\n\nCode\n# load packages\nlibrary(pracma)\nlibrary(dplyr)\nlibrary(ggplot2)\nrequire(gridExtra)\nlibrary(GGally)\nlibrary(cmdstanr)\nlibrary(rstan)\nlibrary(knitr)\nlibrary(reshape2)\nlibrary(bayesplot)\nlibrary(posterior)\n\n# load data\nDS       &lt;- read.csv(here::here(\"1_data/database_stan_1026.csv\"),header = TRUE, sep = \";\", dec = \".\")\nDS_names &lt;- read.csv(here::here(\"1_data/database_stan_1026_analyte_names.csv\"),header = TRUE, sep = \",\", dec = \".\")\nDS_pKa   &lt;- read.csv(here::here(\"1_data/ACD_pKas.csv\"),header = TRUE, sep = \",\", dec = \".\")\n\nnAnalytes=length(unique(DS$ID))\n\n## Calculating charge of analytes in pH=2.658\npH &lt;- 2.658\npKas &lt;- DS_pKa[,3:5]\nfr &lt;- matrix(rep(0,nAnalytes*4),nAnalytes,4)\ncharge &lt;- DS_pKa[,9:12] + DS_pKa[,13:16]\ncharge_pH &lt;- rep(0,nAnalytes)\nfor(i in 1:nAnalytes){\n  pHmpKa &lt;- cbind(0,log(10)^(pH*rep(1,3)-cumsum(pKas[i,])))\n  fr[i, ] &lt;- as.matrix(exp(pHmpKa)/sum(exp(pHmpKa)))\n  charge_pH[i] &lt;- charge[i,which.max(fr[i,])]\n}\n#charge_PH_d &lt;- data.frame(charge_pH)\nrm(pKas,pHmpKa)\n\nDS$compound &lt;- with(DS, ifelse(DS$ID %in% which(charge_pH&lt;0), \"-1\",\n                                 ifelse(DS$ID %in% which(charge_pH==0), \"0\", \"1\")))\n\nggplot(DS) + geom_line(aes(concentration, logk, group=ID,color = compound), alpha = 0.5) + \n  theme_gray() + theme(legend.title = element_text(size=12, color = \"black\", face=\"bold\"),\n                          legend.text = element_text(colour=\"black\", size = 11),\n                          axis.text = element_text(colour=\"black\", size = 11),\n                          axis.title = element_text(colour=\"black\", size = 14)) + \n  guides(colour = guide_legend(override.aes = list(size=2))) +\n  scale_color_manual(labels = c(\"acid\", \"neutral\", \"base\"),values=c(\"red\", \"yellow\", \"blue\"))+\n  labs(y=expression(\"log k\"[\"Obs\"]), x = expression(varphi),colour = \"Compound\")\n\n\n\n\n\nTo obtain an approximate range of model parameters, the data of each analyte separately were fitted, and then combined the individual parameter estimates (the two-stage approach). Analyte-specific chromatographic parameters were estimated for each analyte using the Neue model and least square procedure assuming \\(S_2 = 2\\) for all analytes. This assumption was necessary to obtain stable estimates for all analytes. Then, a linear regression procedure was used to determine the parameters of a regression line between \\(\\log k_{w,i}\\) and \\(\\log P_i\\) as well as between \\(\\log k_{a,i}\\) and \\(\\log P_i\\) separately for neutral and ionized forms of analyte.\n\n\nCode\ninitial_param &lt;- matrix(NA,nAnalytes,3)\nfor(i in 1:nAnalytes){\n  if(length(DS$concentration[which(DS$ID==i)])==1){\n    initial_param[i,2] &lt;- polyfit(-16*DS$concentration[which(DS$ID==i)]/(1+2*DS$concentration[which(DS$ID==i)]),\n                                   DS$logk[which(DS$ID==i)],0)\n    initial_param[i,1] &lt;- -16\n  }else{\n    initial_param[i,1:2] = \n      polyfit(DS$concentration[which(DS$ID==i)]/(1+2*DS$concentration[which(DS$ID==i)]),\n              DS$logk[which(DS$ID==i)],1)\n  }\n}\n\ninitial_param[,3] &lt;- rep(2,nAnalytes)\n\nID        &lt;- unique(DS$ID)\nlogP_ACD  &lt;- DS$logP_ACD[!duplicated(DS$ID)]\nlogkw     &lt;- initial_param[,2]\nlogka     &lt;- initial_param[,2] + initial_param[,1]/3\nlogS2     &lt;- log10(initial_param[,3])\n\nParameters_basic_fit  &lt;-  data.frame(ID,logP_ACD,logkw,logka,logS2)\nrm(ID,logkw,logka,logS2,initial_param)\n\np_neutral_logkw = polyfit(Parameters_basic_fit$logP_ACD[which(charge_pH==0&!is.nan(Parameters_basic_fit$logP_ACD))], \n                          Parameters_basic_fit$logkw[which(charge_pH==0&!is.nan(Parameters_basic_fit$logP_ACD))],1)\np_charged_logkw = polyfit(Parameters_basic_fit$logP_ACD[which(charge_pH==1&!is.nan(Parameters_basic_fit$logP_ACD))], \n                          Parameters_basic_fit$logkw[which(charge_pH==1&!is.nan(Parameters_basic_fit$logP_ACD))],1)\n\nggplot() + geom_point(aes(logP_ACD, Parameters_basic_fit$logkw, color = as.factor(charge_pH)), alpha = 0.5)+\n  scale_color_manual(values=c(\"red\",\"tomato\",\"yellow\",\"skyblue\",\"blue\")) +\n  geom_line(aes(seq(-3,8,by=0.1),polyval(p_neutral_logkw,seq(-3,8,by=0.1))),size=1,colour=\"brown\") +\n  geom_line(aes(seq(-3,8,by=0.1),polyval(p_charged_logkw,seq(-3,8,by=0.1))),size=1,colour=\"navy\") +\n  labs(x = \"log P\", y = expression(\"log k\"[\" w \"]), color = \"Charge\") + \n  theme(legend.title = element_text(size=14, color = \"black\", face=\"bold\"),\n                        legend.text = element_text(colour=\"black\", size = 11),\n                        axis.title=element_text(size=13),\n                        axis.text = element_text(colour=\"black\", size = 11)) +\n  theme_gray()\n\n\nWarning: Removed 1 rows containing missing values (geom_point).\n\n\n\n\n\nCode\np_neutral_logka = polyfit(Parameters_basic_fit$logP_ACD[which(charge_pH==0&!is.nan(Parameters_basic_fit$logP_ACD))], \n                          Parameters_basic_fit$logka[which(charge_pH==0&!is.nan(Parameters_basic_fit$logP_ACD))],1)\np_charged_logka = polyfit(Parameters_basic_fit$logP_ACD[which(charge_pH==1&!is.nan(Parameters_basic_fit$logP_ACD))], \n                          Parameters_basic_fit$logka[which(charge_pH==1&!is.nan(Parameters_basic_fit$logP_ACD))],1)\n\nggplot() + geom_point(aes(logP_ACD, Parameters_basic_fit$logka, color = as.factor(charge_pH)), alpha = 0.5)+\n  scale_color_manual(values=c(\"red\",\"tomato\",\"yellow\",\"skyblue\",\"blue\")) +\n  geom_line(aes(seq(-3,8,by=0.1),polyval(p_neutral_logka,seq(-3,8,by=0.1))),size=1,colour=\"brown\") +\n  geom_line(aes(seq(-3,8,by=0.1),polyval(p_charged_logka,seq(-3,8,by=0.1))),size=1,colour=\"navy\") +\n  labs(x = \"logP\", y = expression(\"logk\"[\" a \"]), color = \"Charge\") + \n  theme(legend.title = element_text(size=14, color = \"black\", face=\"bold\"),\n        legend.text = element_text(colour=\"black\", size = 11),\n        axis.title=element_text(size=13),\n        axis.text = element_text(colour=\"black\", size = 11)) \n\n\nWarning: Removed 1 rows containing missing values (geom_point).\n\n\n\n\n\nBeta(1,1),\\ {k{w_1}} N(1.054, 1.136), {k{w_2}} N(2.053, 1.487),\\ {k{a_1}} N(-3.437, 1.062), {k{a_2}} N(-1.885, 1.006),\\ {S{2_1}}, N(,0.2), {S{2_2}}, N(,0.2), \\ {k{w_1}} N(0.7,0.25), {k{w_2}} N(0.7,0.25),\\ {k{a_1}} N(0.3,0.25), {k{a_2}} N(0.3,0.25), \\ {S{2_1}} N(0,0.25), {S{2_2}} N(0,0.25), \\ N(2.56,1.92), \\ {k{w_1}}{+}(0,1.136), , {k_{a_1}}{+}(0,1.487), , {S_{2_1}}{+}(0,0.2), \\ {k_{w_2}}{+}(0,1.062), , {k_{a_2}}{+}(0,1.006), , {S_{2_2}} _{+}(0,0.2), \\\n\\[\\begin{bmatrix}\n1 & \\rho_{1,2_1} & \\rho_{1,3_1} \\\\\n\\rho_{2,1_1} & 1 & \\rho_{2,3_1} \\\\\n\\rho_{3,1_1} & \\rho_{3,2_1} & 1\n\\end{bmatrix}\\]\n,\n\\[\\begin{bmatrix}\n1 & \\rho_{1,2_2} & \\rho_{1,3_2} \\\\\n\\rho_{2,1_2} & 1 & \\rho_{2,3_2} \\\\\n\\rho_{3,1_2} & \\rho_{3,2_2} & 1\n\\end{bmatrix}\\]\nLKJ(1), \\ _{+}(0,0.067). \\end{align*}"
  },
  {
    "objectID": "model_1.html#analysis",
    "href": "model_1.html#analysis",
    "title": "",
    "section": "Analysis",
    "text": "Analysis\nModel was constructed and implemented in the Stan program.\n\n\nCode\nfunctions{\n  real hplcmodel(real fi, real logkw, real logka, real logS2A){\n    \n    real logk;                  // retention factor\n    real S1;                        // slope coefficient\n    \n    S1 = (logkw - logka)*(1+10^logS2A);\n    logk = logkw - S1 * fi / (1 + 10^logS2A * fi);\n    \n    return logk;\n  }\n}\n\ndata{\n  \n  int nAnalytes;              // number of analytes\n  int nObs;                     // number of observations\n  int analyte[nObs];      // analytes indexes\n  vector[nObs] logkObs; // observed retention factors\n  vector[nObs] fi;          // organic modifier content in the mobile phase\n  real logP[nAnalytes];           // molecular descriptor     \n  int idxmissing[nAnalytes];      // indexes of logP missing value \n  int&lt;lower = 0, upper = 1&gt; run_estimation; // 0 for prior predictive, 1 for estimation\n}\n\nparameters{\n  \n  real&lt;lower=0, upper=1&gt; lambda;  // fraction of analytes belonging to the first cluster\n  vector[2]  logkwHat;                      // mean value of logkw in population\n  ordered[2] logkaHat;            // mean value of logka in population\n  vector[2] logS2AHat;                      // mean curvature coefficient for acetonitrile in population\n  \n  real&lt;lower = 0&gt; sigma;                  // standard deviation for residuals\n  vector&lt;lower = 0&gt;[3] omega1;      // diagonal elements of variance-covariance matrix \n  corr_matrix[3] rho1;                      // correlation matrix\n  vector&lt;lower = 0&gt;[3] omega2;      // diagonal elements of variance-covariance matrix \n  corr_matrix[3] rho2;                      // correlation matrix\n  real beta[6];                                   // coefficient value for molecular descriptor\n  real logPmissing[nAnalytes];    // logP missing values\n  vector[3] param[nAnalytes];\n\n}\n\ntransformed parameters{\n \n  vector[3] miu1[nAnalytes];     \n  vector[3] miu2[nAnalytes];     \n  real logkw[nAnalytes];     // analyte- specific logkw\n  real logka[nAnalytes];     // analyte- specific logka\n  real logS2A[nAnalytes];    // analyte- specific curvature coefficient\n  cov_matrix[3] Omega1;          // variance-covariance matrix\n  cov_matrix[3] Omega2;          // variance-covariance matrix\n  vector[nObs] logkHat;          // mean value of logk in population\n  vector[2] lps[nAnalytes];\n  real log_Z[nAnalytes];\n  real logPr1[nAnalytes];\n\n  Omega1 = quad_form_diag(rho1, omega1);    // diag_matrix(omega) * rho * diag_matrix(omega)\n  Omega2 = quad_form_diag(rho2, omega2);    // diag_matrix(omega) * rho * diag_matrix(omega)\n\n  for(j in 1:nAnalytes){\n    miu1[j,1]  = logkwHat[1]  +  beta[1] * ((1-idxmissing[j])*logP[j]+idxmissing[j]*logPmissing[j]);\n    miu2[j,1]  = logkwHat[2]  +  beta[2] * ((1-idxmissing[j])*logP[j]+idxmissing[j]*logPmissing[j]);\n    miu1[j,2]  = logkaHat[1]  +  beta[3] * ((1-idxmissing[j])*logP[j]+idxmissing[j]*logPmissing[j]); \n    miu2[j,2]  = logkaHat[2]  +  beta[4] * ((1-idxmissing[j])*logP[j]+idxmissing[j]*logPmissing[j]); \n    miu1[j,3]  = logS2AHat[1] +  beta[5] * ((1-idxmissing[j])*logP[j]+idxmissing[j]*logPmissing[j]);\n    miu2[j,3]  = logS2AHat[2] +  beta[6] * ((1-idxmissing[j])*logP[j]+idxmissing[j]*logPmissing[j]);\n  }\n\n    for(j in 1:nAnalytes){\n        logkw[j]  = param[j, 1] ;\n        logka[j]  = param[j, 2] ;\n        logS2A[j] = param[j, 3] ;\n    }\n  \n  for(i in  1:nAnalytes){\n  lps[i,1] = log(lambda)   +  multi_student_t_lpdf(param[i]|7, miu1[i],Omega1);\n  lps[i,2] = log1m(lambda) +  multi_student_t_lpdf(param[i]|7, miu2[i],Omega2);\n  log_Z[i] = log_sum_exp(lps[i,1:2]);\n  logPr1[i] = lps[i,1] - log_Z[i];\n  }\n\n  for(i in 1:nObs){\n    logkHat[i] = hplcmodel(fi[i], logkw[analyte[i]], logka[analyte[i]], logS2A[analyte[i]]);\n }\n  \n}\nmodel{\n  \n  logkwHat[1]  ~ normal(1.054, 1.136);\n  logkwHat[2]  ~ normal(2.053, 1.487);\n  logkaHat[1]  ~ normal(-3.437, 1.062);\n  logkaHat[2]  ~ normal(-1.885, 1.006);\n  logS2AHat[1] ~ normal(log10(2), 0.2);\n  logS2AHat[2] ~ normal(log10(2), 0.2);\n\n  beta[1] ~ normal(0.7,0.25);\n  beta[2] ~ normal(0.7,0.25);\n  beta[3] ~ normal(0.3,0.25);\n  beta[4] ~ normal(0.3,0.25);\n  beta[5] ~ normal(0,0.25);\n  beta[6] ~ normal(0,0.25);\n\n  logPmissing ~ normal(2.56,1.92); // based on logP fit\n\n  omega1[1] ~ normal(0,1.136);\n  omega1[2] ~ normal(0,1.487);\n  omega1[3] ~ normal(0,0.2);\n  rho1   ~ lkj_corr(1);\n  omega2[1] ~ normal(0,1.062);\n  omega2[2] ~ normal(0,1.006);\n  omega2[3] ~ normal(0,0.2);\n  rho2   ~ lkj_corr(1);\n  sigma  ~ normal(0,0.067);\n  lambda ~ beta(1,1);\n\n  for(i in  1:nAnalytes){\n  target += log_Z[i];\n  }\n  \n  if(run_estimation==1){\n  logkObs ~ student_t(7,logkHat, sigma);    // observations\n  }\n}\n\ngenerated quantities{\n    \n  real logkCond[nObs];\n  real log_lik[nObs];\n  real logkHatPred[nObs];\n  real log_likPred[nObs];\n  vector[3] paramPred[nAnalytes];    \n  \n  for(j in 1:nAnalytes){\n    if(bernoulli_rng(lambda) == 1){\n      paramPred[j] =  multi_student_t_rng(7,miu1[j],Omega1);\n    }\n    else{\n      paramPred[j] =  multi_student_t_rng(7,miu2[j],Omega2);\n    }\n  }\n  \n    for(i in 1:nObs){\n    logkCond[i] = student_t_rng(7,logkHat[i], sigma);\n    log_lik[i]  = student_t_lpdf(logkObs[i] | 7,logkHat[i], sigma);\n    logkHatPred[i]  = hplcmodel(fi[i], paramPred[analyte[i],1], paramPred[analyte[i],2], paramPred[analyte[i],3]);\n    log_likPred[i] = student_t_lpdf(logkObs[i] | 7,logkHatPred[i], sigma); \n  }\n \n}\n\n\nThen, the data was added to it and the initial values of the model parameters were determined. In the end, the model was fitted.\n\n\nCode\n# indicating missing value of log P\nidxmissing &lt;- rep(0,1026)\nidxmiss &lt;- which(is.nan(DS$logP_ACD[!duplicated(DS$ID)]))\nidxmissing[idxmiss] &lt;- 1\n\nDS$logP_ACD[which(DS$ID %in% idxmiss)] &lt;- 0\n\nlogP=DS$logP_ACD[!duplicated(DS$ID)]\nnObs=length(DS$ID)\nanalyte=DS$ID\nlogkObs=DS$logk\nfi=DS$concentration\nfiplot=seq(0,1,0.1)\nnfiplot=length(fiplot)\nrun_estimation=1\n\n# data to model\ndatastruct_prior = with(DS,\n                    list(logP=DS$logP_ACD[!duplicated(DS$ID)],\n                       idxmissing=idxmissing,\n                       nAnalytes=nAnalytes,\n                       nObs=nObs,\n                       analyte=DS$ID,\n                       logkObs=DS$logk, \n                       fi=DS$concentration,\n                       nfiplot=length(fi),\n                       fiplot=fi,\n                       run_estimation=0))\n\ndatastruct = with(DS,\n                  list(logP=DS$logP_ACD[!duplicated(DS$ID)],\n                       idxmissing=idxmissing,\n                       nAnalytes=nAnalytes,\n                       nObs=nObs,\n                       analyte=DS$ID,\n                       logkObs=DS$logk, \n                       fi=DS$concentration,\n                       nfiplot=length(fi),\n                       fiplot=fi,\n                       run_estimation=1))\n\n# declaring initial values for each variable in chains\ninit &lt;- function(){\n  list(logkwHat  = rnorm(2,2,0.2),\n       logkaHat  = sort(c(rnorm(1,-4,0.2),rnorm(1,-4,0.2)+max(0,rnorm(1,2,0.5)))),\n       logS2AHat = rnorm(2,log(2),0.2),\n       \n       omega1= c(1,1,1)*exp(rnorm(3,0,0.2)),\n       rho1 = diag(1,3,3),\n       omega2= c(1,1,1)*exp(rnorm(3,0,0.2)),\n       rho2 = diag(1,3,3),\n       \n       beta = c(1,1,0.5,0.5,0,0)*exp(rnorm(6,0,0.2)),\n      \n       lambda=runif(1,0,1),\n\n       param = Parameters_basic_fit[,3:5],\n       sigma  = rlnorm(1,log(0.1),0.2)\n  )\n}\n\n# specifying parameters to analysis \nparametersToPlot &lt;- c(\"logkwHat\",\"logkaHat\",\"logS2AHat\",\"omega1\",\"rho1\",\"omega2\",\"rho2\",\"beta\",\"lambda\",\"sigma\")\notherRVs &lt;- c(\"paramPred\",\"logkw\",\"logka\",\"logS2A\",\"log_lik\",\"logPr1\",\"logkHatPred\",\"log_likPred\")\n\nparameters &lt;- c(parametersToPlot, otherRVs)\nparametersToPlot &lt;- c(\"lp__\", parametersToPlot)\n\n# fitting model\nfit_prior &lt;- stan(file=\"ACN001.stan\",\n            data=datastruct_prior,\n            pars=parameters,\n            iter=2000,\n            warmup=1000,\n            init=init,\n            chains=4,thin=1,control = list(adapt_delta = 0.9,max_treedepth=15))\n\nfit &lt;- stan(file=\"ACN001.stan\",\n                   data=datastruct,\n                   pars=parameters,\n                   iter=2000,\n                   warmup=1000,\n                   init=init,\n                   chains=4,thin=1,control = list(max_treedepth=12))\n\n\nBelow code preapering data to fit the model in supercomputer:\n\n\nCode\nlogP=DS$logP_ACD[!duplicated(DS$ID)]\nnAnalytes=length(unique(DS$ID))\nnObs=length(DS$ID)\nanalyte=DS$ID\nlogkObs=DS$logk\nfi=DS$concentration\nfiplot=seq(0,1,0.1)\nnfiplot=length(fiplot)\nrun_estimation=1\n\nstan_rdump(c(\"logP\",\n             \"nAnalytes\", \n             \"nObs\",\n             \"idxmissing\", \n             \"analyte\", \n             \"logkObs\", \n             \"fi\",\n             \"nfiplot\",\n             \"fiplot\",\n             \"run_estimation\"),\n           file=\"3_model_1/model.data.R\")\n\n\nWarning in stan_rdump(c(\"logP\", \"nAnalytes\", \"nObs\", \"idxmissing\", \"analyte\", :\nobjects not found: idxmissing\n\n\nCode\nfor(i in 1:10){\n  logkwHat  = rnorm(2,2,0.2)\n  logkaHat  = sort(c(rnorm(1,-4,0.2),rnorm(1,-4,0.2)+max(0,rnorm(1,2,0.5))))\n  logS2AHat = rnorm(2,log(2),0.2)\n  omega1= c(1,1,1)*exp(rnorm(3,0,0.2))\n  rho1 = diag(1,3,3)\n  omega2= c(1,1,1)*exp(rnorm(3,0,0.2))\n  rho2 = diag(1,3,3)\n  beta = c(1,1,0.5,0.5,0,0)*exp(rnorm(6,0,0.2))\n  lambda=runif(1,0,1)\n  param = Parameters_basic_fit[,3:5]\n  sigma  = rlnorm(1,log(0.1),0.2)\n  \n  stan_rdump(c(\"logkwHat\",\"logkaHat\",\"logS2AHat\",\"beta\",\"rho1\",\"rho2\",\"lambda\",\"omega1\",\"omega2\",\"sigma\"),\n             file=paste(\"3_model_1/model_\", i, \".init.R\", sep=\"\"))\n}"
  },
  {
    "objectID": "model_1.html#summary-of-model-parameters",
    "href": "model_1.html#summary-of-model-parameters",
    "title": "",
    "section": "Summary of model parameters",
    "text": "Summary of model parameters\nCode for print summary of parameters from supercomputer:\n\n\nCode\nfit &lt;- cmdstanr::as_cmdstan_fit(c('3_model_1/output_1.csv',\n                                  '3_model_1/output_2.csv',\n                                  '3_model_1/output_3.csv',\n                                  '3_model_1/output_4.csv',\n                                  '3_model_1/output_5.csv',\n                                  '3_model_1/output_6.csv',\n                                  '3_model_1/output_7.csv',\n                                  '3_model_1/output_8.csv',\n                                  '3_model_1/output_9.csv',\n                                  '3_model_1/output_10.csv'))\n\nfit$print(c(\"logkwHat\",\"logkaHat\",\"logS2AHat\",\"beta\",\"rho1\",\"rho2\",\"lambda\",\"omega1\",\"omega2\",\"sigma\"), max_rows = 26)\n\n\nCode for print summary of parameters from computer:\n\n\nCode\nload(\"3_model_1/Fit.Rsave\")\nload(\"3_model_1/Fit_sample.Rsave\")\n\nprint(fit,pars=c(\"logkwHat\",\"logkaHat\",\"logS2AHat\",\"beta\",\"rho1\",\"rho2\",\"lambda\",\"omega1\",\"omega2\",\"sigma\"))\n\n\nInference for Stan model: ACN001.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n              mean se_mean   sd  2.5%   25%   50%   75% 97.5% n_eff Rhat\nlogkwHat[1]   1.51       0 0.12  1.28  1.44  1.51  1.59  1.75  2438 1.00\nlogkwHat[2]   2.51       0 0.16  2.19  2.40  2.51  2.61  2.81  2013 1.00\nlogkaHat[1]  -2.75       0 0.10 -2.95 -2.82 -2.75 -2.68 -2.57  1504 1.00\nlogkaHat[2]  -1.10       0 0.02 -1.15 -1.12 -1.10 -1.09 -1.06  5120 1.00\nlogS2AHat[1]  0.46       0 0.03  0.40  0.44  0.46  0.47  0.51  1584 1.00\nlogS2AHat[2]  0.61       0 0.02  0.57  0.60  0.61  0.62  0.65  2181 1.00\nbeta[1]       0.64       0 0.04  0.56  0.61  0.64  0.66  0.71  2719 1.00\nbeta[2]       0.92       0 0.05  0.82  0.89  0.92  0.95  1.03  1333 1.00\nbeta[3]       0.14       0 0.03  0.08  0.12  0.14  0.16  0.20  1721 1.00\nbeta[4]       0.18       0 0.01  0.16  0.17  0.18  0.18  0.19  5305 1.00\nbeta[5]      -0.02       0 0.01 -0.04 -0.03 -0.02 -0.02 -0.01  1634 1.00\nbeta[6]      -0.04       0 0.01 -0.05 -0.05 -0.04 -0.04 -0.03  1463 1.01\nrho1[1,1]     1.00     NaN 0.00  1.00  1.00  1.00  1.00  1.00   NaN  NaN\nrho1[1,2]     0.23       0 0.06  0.12  0.19  0.23  0.28  0.35  2627 1.00\nrho1[1,3]     0.16       0 0.06  0.04  0.12  0.16  0.21  0.28  2345 1.00\nrho1[2,1]     0.23       0 0.06  0.12  0.19  0.23  0.28  0.35  2627 1.00\nrho1[2,2]     1.00       0 0.00  1.00  1.00  1.00  1.00  1.00  4141 1.00\nrho1[2,3]     0.60       0 0.04  0.51  0.57  0.60  0.63  0.68  1909 1.00\nrho1[3,1]     0.16       0 0.06  0.04  0.12  0.16  0.21  0.28  2345 1.00\nrho1[3,2]     0.60       0 0.04  0.51  0.57  0.60  0.63  0.68  1909 1.00\nrho1[3,3]     1.00       0 0.00  1.00  1.00  1.00  1.00  1.00  1457 1.00\nrho2[1,1]     1.00     NaN 0.00  1.00  1.00  1.00  1.00  1.00   NaN  NaN\nrho2[1,2]     0.12       0 0.06 -0.01  0.08  0.12  0.16  0.24  1992 1.00\nrho2[1,3]     0.57       0 0.04  0.48  0.54  0.57  0.60  0.66  1839 1.00\nrho2[2,1]     0.12       0 0.06 -0.01  0.08  0.12  0.16  0.24  1992 1.00\nrho2[2,2]     1.00       0 0.00  1.00  1.00  1.00  1.00  1.00  3948 1.00\nrho2[2,3]    -0.40       0 0.06 -0.51 -0.44 -0.40 -0.37 -0.29  1988 1.00\nrho2[3,1]     0.57       0 0.04  0.48  0.54  0.57  0.60  0.66  1839 1.00\nrho2[3,2]    -0.40       0 0.06 -0.51 -0.44 -0.40 -0.37 -0.29  1988 1.00\nrho2[3,3]     1.00       0 0.00  1.00  1.00  1.00  1.00  1.00  1187 1.00\nlambda        0.46       0 0.02  0.43  0.45  0.46  0.47  0.50  4038 1.00\nomega1[1]     1.13       0 0.06  1.02  1.09  1.13  1.17  1.25  2095 1.00\nomega1[2]     0.80       0 0.05  0.72  0.77  0.80  0.83  0.90  1474 1.00\nomega1[3]     0.23       0 0.01  0.20  0.22  0.23  0.23  0.25  1434 1.00\nomega2[1]     1.41       0 0.07  1.28  1.36  1.41  1.45  1.55  1654 1.00\nomega2[2]     0.20       0 0.01  0.18  0.19  0.20  0.21  0.22  2309 1.00\nomega2[3]     0.18       0 0.01  0.16  0.17  0.18  0.18  0.20  1884 1.00\nsigma         0.03       0 0.00  0.03  0.03  0.03  0.03  0.03  1250 1.00\n\nSamples were drawn using NUTS(diag_e) at Wed Nov 04 04:21:39 2020.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1)."
  },
  {
    "objectID": "model_1.html#goodness-of-fit",
    "href": "model_1.html#goodness-of-fit",
    "title": "",
    "section": "Goodness of fit",
    "text": "Goodness of fit\n\n\nCode\nlibrary(metRology) # function rt.scaled\n\nhplc &lt;- function(fi,logkw,logka,logS2A){\n  S1 = (logkw - logka)*(1+10^logS2A)\n  logk = logkw - S1 * fi / (1 + 10^logS2A * fi)\n  return(logk)\n}\n\nlogkHatCond &lt;-array(rep(5097*4000),dim=c(4000,5097))\nlogkCond &lt;-array(rep(5097*4000),dim=c(4000,5097))\nfor(j in 1:nObs){\n    for(k in 1:4000){\n      logkHatCond[k,j]  = hplc(DS$concentration[j], fit_sample$logkw[k,DS$ID[j]],\n                                     fit_sample$logka[k,DS$ID[j]], fit_sample$logS2A[k,DS$ID[j]])\n      logkCond[k,j]     = rt.scaled(1,7,logkHatCond[k,j], fit_sample$sigma[k])\n    }\n}\n\nlogkPred &lt;-array(rep(5097*4000),dim=c(4000,5097))\nfor(j in 1:nObs){\n  for(k in 1:4000){\n    logkPred[k,j]       = rt.scaled(1,7,fit_sample$logkHatPred[k,j], fit_sample$sigma[k])\n  }\n}\n\npar(mfrow=c(1,2))\nplot(apply(logkCond,2,mean),DS$logk,cex.lab=1.2,xlim=c(-4,6),ylim=c(-3,3),pch=20,col=\"blue\",ylab=expression(\"Log k\"[Obs]),xlab=expression(\"Log k\"[Pred]))\nlines(seq(-4,6,by=0.1),seq(-4,6,by=0.1),lwd=2)\nplot(apply(logkPred,2,mean),DS$logk,cex.lab=1.2,xlim=c(-4,6),ylim=c(-3,3),pch=20,col=\"blue\",ylab=expression(\"Log k\"[Obs]),xlab=expression(\"Log k\"[Pred]))\nlines(seq(-4,6,by=0.1),seq(-4,6,by=0.1),lwd=2)\n\n\n\n\n\n\nWAIC\n\n\nCode\nlibrary(loo)\nwaic(extract_log_lik(fit)) # to samo co: waic(fit_sample$log_lik)\n\n\nWarning: \n2244 (44.0%) p_waic estimates greater than 0.4. We recommend trying loo instead.\n\n\n\nComputed from 4000 by 5097 log-likelihood matrix\n\n          Estimate    SE\nelpd_waic   7767.1 183.9\np_waic      3619.4 165.5\nwaic      -15534.1 367.8\n\n2244 (44.0%) p_waic estimates greater than 0.4. We recommend trying loo instead. \n\n\nCode\nloo(extract_log_lik(fit))\n\n\nWarning: Relative effective sample sizes ('r_eff' argument) not specified.\nFor models fit with MCMC, the reported PSIS effective sample sizes and \nMCSE estimates will be over-optimistic.\n\n\nWarning: Some Pareto k diagnostic values are too high. See help('pareto-k-diagnostic') for details.\n\n\n\nComputed from 4000 by 5097 log-likelihood matrix\n\n         Estimate    SE\nelpd_loo   7385.6 120.0\np_loo      4000.8  94.2\nlooic    -14771.2 240.0\n------\nMonte Carlo SE of elpd_loo is NA.\n\nPareto k diagnostic values:\n                         Count Pct.    Min. n_eff\n(-Inf, 0.5]   (good)     2919  57.3%   83        \n (0.5, 0.7]   (ok)        917  18.0%   55        \n   (0.7, 1]   (bad)       912  17.9%   11        \n   (1, Inf)   (very bad)  349   6.8%   1         \nSee help('pareto-k-diagnostic') for details."
  },
  {
    "objectID": "model_1.html#predictions",
    "href": "model_1.html#predictions",
    "title": "",
    "section": "Predictions",
    "text": "Predictions\nIndividual predictions\n\n\nCode\nlibrary(ggpubr)\nnazwy &lt;- c(\"Caffeine\",\"Chlorpropamide\",\"Doxepin hydrochloride\",\"Perphenazine\",\n  \"Pindolol\",\"Phenylbutazone\",\"Procainamide hydrochloride\",\"Retinoic acid\",\n  \"Sulfaphenazole\",\"Tolbutamide\",\"Ketoprofen\",\"Indomethacin\")\nl_nazwy &lt;- which(DS_names$Analyte[!duplicated(DS_names$ID)] %in% nazwy)\n\n\n\n\nCode\nlogkHatPlotACond &lt;-array(rep(0,11*1026*4000),dim=c(4000,1026,11))\nlogkPlotACond &lt;-array(rep(0,11*1026*4000),dim=c(4000,1026,11))\n\nfor(j in 1:nAnalytes){\n  for(z in 1:nfiplot){\n    for(k in 1:4000){\n      logkHatPlotACond[k,j,z]   = hplc(fiplot[z], fit_sample$logkw[k,j],\n                                     fit_sample$logka[k,j], fit_sample$logS2A[k,j])\n      logkPlotACond[k,j,z]      = rt.scaled(1,7,logkHatPlotACond[k,j,z], fit_sample$sigma[k])\n    }\n  }\n}\n\nplots &lt;- list()\nfor(i in 1:nAnalytes){\n  l &lt;- apply(drop(logkPlotACond[,i,]), MARGIN = 2, FUN = quantile, probs = c(.025,.5,.975))\n  logk_prct &lt;- as.data.frame(cbind(rep(i,11),fiplot,t(l)))\n  colnames(logk_prct)&lt;-c(\"ID\",\"concentration\",\"low\",\"median\",\"high\")\n  plots[[i]] &lt;- ggplot()+ xlim(0,1) +\n    geom_point(data=subset(DS, ID == i), aes(x = concentration, y = logk), col=\"blue\") +\n    geom_line(data=subset(logk_prct, ID == i), aes(x = fiplot, y = median), col=\"blue\") +\n    geom_ribbon(data=subset(logk_prct, ID == i), aes(x = fiplot, \n                                                     ymin = low, \n                                                     ymax = high), alpha = 0.25, fill=\"blue\")+\n    coord_cartesian(ylim = c(-3, 4)) + \n    labs(title = paste(DS$Names[which(DS$ID==i)]),\n         x = NULL,\n         y = NULL) +\n    theme(text = element_text(size = 9), axis.text = element_text(size = 9),\n          legend.position = \"none\", strip.text = element_text(size = 6)) \n}\nfigure1 &lt;- ggarrange(plotlist = plots[l_nazwy], nrow=3,ncol = 4)\nannotate_figure(figure1,\n                bottom = text_grob(expression(varphi)),\n                left = text_grob(\"log k\", rot = 90))\n\n\n\n\n\nPopulation predictions\n\n\nCode\nlogkHatPlotAPred &lt;-array(rep(0,11*1026*4000),dim=c(4000,1026,11))\nlogkPlotAPred &lt;-array(rep(0,11*1026*4000),dim=c(4000,1026,11))\n\nfor(j in 1:nAnalytes){\n  for(z in 1:nfiplot){\n    for(k in 1:4000){\n      logkHatPlotAPred[k,j,z]   = hplc(fiplot[z], fit_sample$paramPred[k,j,1],\n                                     fit_sample$paramPred[k,j,2], fit_sample$paramPred[k,j,3])\n      logkPlotAPred[k,j,z]      = rt.scaled(1,7,logkHatPlotAPred[k,j,z], fit_sample$sigma[k])\n    }\n  }\n}\nsave(logkPlotAPred,\"4_model_2/logkPlotAPred.Rsave\")\n\n\n\n\nCode\nload(\"3_model_1/logkPlotAPred.Rsave\")\nplots &lt;- list()\nfor(i in 1:nAnalytes){\n  l &lt;- apply(drop(logkPlotAPred[,i,]), MARGIN = 2, FUN = quantile, probs = c(.025,.5,.975))\n  logk_prct &lt;- as.data.frame(cbind(rep(i,11),fiplot,t(l)))\n  colnames(logk_prct)&lt;-c(\"ID\",\"concentration\",\"low\",\"median\",\"high\")\n  plots[[i]] &lt;- ggplot()+ xlim(0,1) +\n    geom_point(data=subset(DS, ID == i), aes(x = concentration, y = logk), col=\"blue\") +\n    geom_line(data=subset(logk_prct, ID == i), aes(x = fiplot, y = median), col=\"red\") +\n    geom_ribbon(data=subset(logk_prct, ID == i), aes(x = fiplot, \n                                                     ymin = low, \n                                                     ymax = high), alpha = 0.25, fill=\"red\")+\n    coord_cartesian(ylim = c(-3, 4)) + \n    labs(title = paste(DS$Names[which(DS$ID==i)]),\n         x = NULL,\n         y = NULL) +\n    theme(text = element_text(size = 9), axis.text = element_text(size = 9),\n          legend.position = \"none\", strip.text = element_text(size = 6)) \n}\nfigure1 &lt;- ggarrange(plotlist = plots[l_nazwy], nrow=3,ncol = 4)\nannotate_figure(figure1,\n                bottom = text_grob(expression(varphi)),\n                left = text_grob(\"log k\", rot = 90))"
  },
  {
    "objectID": "model_1.html#probability-beloging-to-clusters",
    "href": "model_1.html#probability-beloging-to-clusters",
    "title": "",
    "section": "Probability beloging to clusters",
    "text": "Probability beloging to clusters\nThe chart below shows the values of the probabilities of belonging of individual analytes to the first cluster.\n\n\nCode\nvector &lt;- apply(fit_sample$logPr1,2,mean)\nprobability_I_cluster &lt;- 10^(vector)\ndata &lt;- data.frame(unique(DS$ID),probability_I_cluster)\n\nggplot(data,aes(data[,1],data[,2]))+geom_point()+xlab(\"analyte index\")+ylab(\"probability\")\n\n\n\n\n\nResidual distributions of initial model were determined taking into account belonging to the first (blue) and the second (red) cluster.\n\n\nCode\ndata_cluster &lt;- cbind(DS$ID[!duplicated(DS$ID)],probability_I_cluster)\ncluster &lt;- as.vector(ifelse(probability_I_cluster&gt;0.5,\"I\",\"II\"))\n\nload(\"2_initial_model/Fit_sample.Rsave\")\n\neta_logka &lt;- apply(drop(fit_sample$eta[,,1]), MARGIN = 2, FUN = mean)\neta_logS2A &lt;- apply(drop(fit_sample$eta[,,2]), MARGIN = 2, FUN = mean)\neta_logkw &lt;- apply(drop(fit_sample$eta[,,3]), MARGIN = 2, FUN = mean)\n\nDS_corr &lt;- as.data.frame(cbind(eta_logka,eta_logS2A,eta_logkw,cluster))\ncolnames(DS_corr) &lt;- c(\"eta_logka\",\"eta_logS2A\",\"eta_logkw\",\"cluster\")\nDS_corr[,1] &lt;-as.numeric(as.character(DS_corr[,1]))\nDS_corr[,2] &lt;-as.numeric(as.character(DS_corr[,2]))\nDS_corr[,3] &lt;-as.numeric(as.character(DS_corr[,3]))\n\nlibrary(GGally)\nlibrary(ggplot2)\n\nggpairs(DS_corr, \n        columns = c(\"eta_logkw\",\"eta_logka\",\"eta_logS2A\"),\n        mapping = aes(color = cluster),\n        columnLabels = c(\"eta[ logk[w]]\",\"eta[ logk[a]]\",\"eta[ logS[2]]\"),\n        labeller = label_parsed\n)+ theme_grey(base_size = 20) +theme(axis.text = element_text(size = 10))"
  },
  {
    "objectID": "model_2.html",
    "href": "model_2.html",
    "title": "",
    "section": "",
    "text": "CodeShow All CodeHide All CodeView Source"
  },
  {
    "objectID": "model_2.html#priors",
    "href": "model_2.html#priors",
    "title": "",
    "section": "Priors",
    "text": "Priors\nIn this model, the same priors as in the model 1 were adopted.\n\\[\\begin{align*}\n\\theta_{\\log k_{w_1}} \\sim N(1.054, 1.136),  \\quad \\theta_{\\log k_{w_2}} \\sim N(2.053, 1.487),\\\\\n\\theta_{\\log k_{a_1}} \\sim N(-3.437, 1.062), \\quad \\theta_{\\log k_{a_2}} \\sim N(-1.885, 1.006),\\\\\n\\theta_{\\log S_{2_1}},  \\sim N(\\log 2,0.2), \\quad \\theta_{\\log S_{2_2}},  \\sim N(\\log 2,0.2), \\\\\n\\beta_{\\log k_{w_1}} \\sim N(0.7,0.25), \\quad \\beta_{\\log k_{w_2}} \\sim N(0.7,0.25),\\\\\n\\beta_{\\log k_{a_1}} \\sim N(0.3,0.25), \\quad \\beta_{\\log k_{a_2}} \\sim N(0.3,0.25), \\\\\n\\beta_{\\log S_{2_1}} \\sim N(0,0.25), \\quad \\beta_{\\log S_{2_2}} \\sim N(0,0.25), \\\\\n\\text{logPmissing} \\sim N(2.56,1.92), \\\\\n\\omega_{\\log k_{w_1}}\\sim \\textnormal{N}_{+}(0,1.136),  \\, \\omega_{\\log k_{a_1}}\\sim \\textnormal{N}_{+}(0,1.487), \\, \\omega_{\\log S_{2_1}}\\sim \\textnormal{N}_{+}(0,0.2), \\\\ \\omega_{\\log k_{w_2}}\\sim \\textnormal{N}_{+}(0,1.062), \\, \\omega_{\\log k_{a_2}}\\sim \\textnormal{N}_{+}(0,1.006), \\, \\omega_{\\log S_{2_2}} \\sim \\textnormal{N}_{+}(0,0.2), \\\\\n\\begin{bmatrix}\n1 & \\rho_{1,2_1} & \\rho_{1,3_1} \\\\\n\\rho_{2,1_1} & 1 & \\rho_{2,3_1} \\\\\n\\rho_{3,1_1} & \\rho_{3,2_1} & 1\n\\end{bmatrix}, \\begin{bmatrix}\n1 & \\rho_{1,2_2} & \\rho_{1,3_2} \\\\\n\\rho_{2,1_2} & 1 & \\rho_{2,3_2} \\\\\n\\rho_{3,1_2} & \\rho_{3,2_2} & 1\n\\end{bmatrix} \\sim LKJ(1), \\\\\n\\sigma \\sim \\textnormal{N}_{+}(0,0.067).\n\\end{align*}\\]\nDue to the implementation of the model in the program, the state was assumed and using the built-in inv_logit function ( \\(\\text{inv_logit}(u)=\\frac{1}{1+e^{-u}}\\)), it was assumed that:\n\\[\\begin{align*}\n\\eta \\sim \\textnormal{Student t}(7,0,0.23).\n\\end{align*}\\]"
  },
  {
    "objectID": "model_2.html#analysis",
    "href": "model_2.html#analysis",
    "title": "",
    "section": "Analysis",
    "text": "Analysis\nModel was constructed and implemented in the Stan program.\n\n\nCode\nfunctions{\n  real hplcmodel(real fi, real logkw, real logka, real logS2A){\n    \n    real logk;                  // retention factor\n    real S1;                        // slope coefficient\n    \n    S1 = (logkw - logka)*(1+10^logS2A);\n    logk = logkw - S1 * fi / (1 + 10^logS2A * fi);\n    \n    return logk;\n  }\n}\n\ndata{\n  int nAnalytes;              // number of analytes\n  int nObs;                     // number of observations\n  int analyte[nObs];        // analytes indexes\n  vector[nObs] logkObs; // observed retention factors\n  vector[nObs] fi;          // organic modifier content in the mobile phase\n  real logP[nAnalytes];         // molecular descriptor      \n  int idxmissing[nAnalytes];    // indexes of logP missing value\n  real&lt;lower=0, upper=1&gt; rawlambdai[nAnalytes];  // ratio of ionized to total concentration of a compound\n  \n  int nfiplot;                                // number of fi for plotting\n  vector[nfiplot] fiplot;               // organic modifier content in the mobile phase\n  \n  int&lt;lower = 0, upper = 1&gt; run_estimation; // 0 for prior predictive, 1 for estimation\n}\n\n\ntransformed data {\n  real oddsi[nAnalytes];\n \nfor(j in 1:nAnalytes){\n  oddsi[j] = logit(rawlambdai[j]);\n}\n}\n\nparameters{\n  ordered[2] logkwHat;                  // mean value of logkw in population\n  ordered[2] logkaHat;          // mean value of logka in population\n  vector[2] logS2AHat;                  // mean curvature coefficient for acetonitrile in population\n\n  real&lt;lower = 0&gt; sigma;                    // standard deviation for residuals\n  vector&lt;lower = 0&gt;[3] omega1;      // diagonal elements of variance-covariance matrix \n  corr_matrix[3] rho1;                    // correlation matrix\n  vector&lt;lower = 0&gt;[3] omega2;    // diagonal elements of variance-covariance matrix \n  corr_matrix[3] rho2;                      // correlation matrix\n  real beta[6];                                   // coefficient value for molecular descriptor\n  real logPmissing[nAnalytes];    // logP Missing values\n  vector[3] param1[nAnalytes];\n  vector[3] param2[nAnalytes];\n  real eta[nAnalytes];\n}\n\ntransformed parameters{\n \n  vector[3] miu1[nAnalytes];     \n  vector[3] miu2[nAnalytes];     \n  real logka[nAnalytes];     // mean value of logka in population\n  real logkw[nAnalytes];     // mean value of logkw in population\n  real logS2A[nAnalytes];    // mean curvature coefficient for acetonitrile in population\n  cov_matrix[3] Omega1;          // variance-covariance matrix\n  cov_matrix[3] Omega2;          // variance-covariance matrix\n  vector[nObs] logkHat;          // mean value of logk in population\n  real&lt;lower=0, upper=1&gt; frac[nAnalytes];\n\n  Omega1 = quad_form_diag(rho1, omega1);    // diag_matrix(omega) * rho * diag_matrix(omega)\n  Omega2 = quad_form_diag(rho2, omega2);    // diag_matrix(omega) * rho * diag_matrix(omega)\n\n  for(j in 1:nAnalytes){\n    miu1[j,1]  = logkwHat[1]  +  beta[1] * ((1-idxmissing[j])*logP[j]+idxmissing[j]*logPmissing[j]);\n    miu2[j,1]  = logkwHat[2]  +  beta[2] * ((1-idxmissing[j])*logP[j]+idxmissing[j]*logPmissing[j]);\n    miu1[j,2]  = logkaHat[1]  +  beta[3] * ((1-idxmissing[j])*logP[j]+idxmissing[j]*logPmissing[j]); \n    miu2[j,2]  = logkaHat[2]  +  beta[4] * ((1-idxmissing[j])*logP[j]+idxmissing[j]*logPmissing[j]); \n    miu1[j,3]  = logS2AHat[1] +  beta[5] * ((1-idxmissing[j])*logP[j]+idxmissing[j]*logPmissing[j]);\n    miu2[j,3]  = logS2AHat[2] +  beta[6] * ((1-idxmissing[j])*logP[j]+idxmissing[j]*logPmissing[j]);\n    frac[j]  = inv_logit(oddsi[j] + eta[j]);\n  }\n\n    for(j in 1:nAnalytes){\n    logkw[j]  = param1[j, 1]*frac[j] + param2[j, 1]*(1-frac[j]);\n    logka[j]  = param1[j, 2]*frac[j] + param2[j, 2]*(1-frac[j]);\n    logS2A[j] = param1[j, 3]*frac[j] + param2[j, 3]*(1-frac[j]);\n    }\n  \n\n  for(i in 1:nObs){\n    logkHat[i] = hplcmodel(fi[i], logkw[analyte[i]], logka[analyte[i]], logS2A[analyte[i]]);\n }\n  \n}\nmodel{\n  \n  logkwHat[1]  ~ normal(1.054, 1.136);\n  logkwHat[2]  ~ normal(2.053, 1.487);\n  logkaHat[1]  ~ normal(-3.437, 1.062);\n  logkaHat[2]  ~ normal(-1.885, 1.006);\n  logS2AHat[1] ~ normal(log10(2), 0.2);\n  logS2AHat[2] ~ normal(log10(2), 0.2);\n\n  beta[1] ~ normal(0.7,0.25);\n  beta[2] ~ normal(0.7,0.25);\n  beta[3] ~ normal(0.3,0.25);\n  beta[4] ~ normal(0.3,0.25);\n  beta[5] ~ normal(0,0.25);\n  beta[6] ~ normal(0,0.25);\n\n  logPmissing ~ normal(2.56,1.92); // based on logP fit\n\n  eta ~ student_t(7,0,0.23);\n\n  omega1[1] ~ normal(0,1.136);\n  omega1[2] ~ normal(0,1.487);\n  omega1[3] ~ normal(0,0.2);\n  rho1   ~ lkj_corr(1);\n  omega2[1] ~ normal(0,1.062);\n  omega2[2] ~ normal(0,1.006);\n  omega2[3] ~ normal(0,0.2);\n  rho2   ~ lkj_corr(1);\n  sigma  ~ normal(0,0.067);\n\n  for(i in  1:nAnalytes){\n  param1[i] ~ multi_student_t(7, miu1[i],Omega1);\n  param2[i] ~ multi_student_t(7, miu2[i],Omega2);\n  }\n  \n  if(run_estimation==1){\n  logkObs ~ student_t(7,logkHat, sigma);    // observations\n  }\n}\n\ngenerated quantities{\n\n  real logkCond[nObs];\n  real log_lik[nObs];\n  real log_likPred[nObs];\n  real logkHatPred[nObs];\n  real logkaPred[nAnalytes];\n  real logkwPred[nAnalytes];\n  real logS2APred[nAnalytes];\n  real&lt;lower=0, upper=1&gt; fracPred[nAnalytes];\n  \n  matrix[nAnalytes,nfiplot] logkHatPlotACond;\n  matrix[nAnalytes,nfiplot] logkPlotACond;\n\n  vector[3] paramPred1[nAnalytes];   \n  vector[3] paramPred2[nAnalytes];\n  \n  for(j in 1:nAnalytes){\n\n  real etaPred[nAnalytes];\n\n  etaPred[j] = student_t_rng(7,0, 0.23);\n  fracPred[j]  = inv_logit(oddsi[j] + etaPred[j]);\n  \n  paramPred1[j] =  multi_student_t_rng(7,miu1[j],Omega1);\n  paramPred2[j] =  multi_student_t_rng(7,miu2[j],Omega2);\n\n  logkwPred[j]  = paramPred1[j, 1]*fracPred[j] + paramPred2[j, 1]*(1-fracPred[j]);\n  logkaPred[j]  = paramPred1[j, 2]*fracPred[j] + paramPred2[j, 2]*(1-fracPred[j]);\n  logS2APred[j] = paramPred1[j, 3]*fracPred[j] + paramPred2[j, 3]*(1-fracPred[j]);\n  }\n  \n  for(i in 1:nObs){\n    logkCond[i] = student_t_rng(7,logkHat[i], sigma);\n    log_lik[i]  = student_t_lpdf(logkObs[i] | 7,logkHat[i], sigma);\n    logkHatPred[i]  = hplcmodel(fi[i], logkwPred[analyte[i]], logkaPred[analyte[i]], logS2APred[analyte[i]]);\n    log_likPred[i] = student_t_lpdf(logkObs[i] | 7,logkHatPred[i], sigma); \n\n  }\n}\n\n\nThen, the data was added to it and the initial values of the model parameters were determined. In the end, the model was fitted.\n\n\nCode\n# load packages\nlibrary(pracma)\nlibrary(dplyr)\nlibrary(ggplot2)\nrequire(gridExtra)\nlibrary(GGally)\nlibrary(cmdstanr)\nlibrary(rstan)\nlibrary(knitr)\nlibrary(reshape2)\nlibrary(bayesplot)\nlibrary(posterior)\n\n# load data\nDS       &lt;- read.csv(here::here(\"1_data/database_stan_1026.csv\"),header = TRUE, sep = \";\", dec = \".\")\nDS_names &lt;- read.csv(here::here(\"1_data/database_stan_1026_analyte_names.csv\"),header = TRUE, sep = \",\", dec = \".\")\nDS_pKa   &lt;- read.csv(here::here(\"1_data/ACD_pKas.csv\"),header = TRUE, sep = \",\", dec = \".\")\n\nnAnalytes=length(unique(DS$ID))\n\n# calculating fractions of analytes in pH=2.658\npH &lt;- 2.658\npKas &lt;- DS_pKa[,3:5]\nfr &lt;- matrix(rep(0,nAnalytes*4),nAnalytes,4)\ncharge &lt;- DS_pKa[,9:12] + DS_pKa[,13:16]\ncharge_pH &lt;- rep(0,nAnalytes)\nlambda &lt;- rep(0,1026)\nfor(i in 1:nAnalytes){\n  cums&lt;-cumsum(c(pKas[i,]))\n  x&lt;-c()\n  x[1]&lt;-1\n  for(j in 1:3){\n    x[j+1]&lt;- 10^(j*pH-cums[j])\n  }\n  fr[i, ] &lt;- as.matrix(x/sum(x))\n  charge_pH[i] &lt;- charge[i,which.max(fr[i,])]\n  lambda[i] &lt;- sum(fr[i,which(charge[i,]==0)])\n}\n\n# calculation of logk versus fi curves\ninitial_param &lt;- matrix(NA,nAnalytes,3)\nfor(i in 1:nAnalytes){\n  if(length(DS$concentration[which(DS$ID==i)])==1){\n    initial_param[i,2] &lt;- polyfit(-16*DS$concentration[which(DS$ID==i)]/(1+2*DS$concentration[which(DS$ID==i)]),\n                                  DS$logk[which(DS$ID==i)],0)\n    initial_param[i,1] &lt;- -16\n  }else{\n    initial_param[i,1:2] = \n      polyfit(DS$concentration[which(DS$ID==i)]/(1+2*DS$concentration[which(DS$ID==i)]),\n              DS$logk[which(DS$ID==i)],1)\n  }\n}\ninitial_param[,3] &lt;- rep(2,nAnalytes)\n\nID        &lt;- unique(DS$ID)\nlogP_ACD  &lt;- DS$logP_ACD[!duplicated(DS$ID)]\nlogkw     &lt;- initial_param[,2]\nlogka     &lt;- initial_param[,2] + initial_param[,1]/3\nlogS2     &lt;- log10(initial_param[,3])\n\nParameters_basic_fit  &lt;-  data.frame(ID,logP_ACD,logkw,logka,logS2)\nrm(ID,logkw,logka,logS2,initial_param)\n\n# indicating missing value of log P\nidxmissing &lt;- rep(0,1026)\nidxmiss &lt;- which(is.nan(DS$logP_ACD[!duplicated(DS$ID)]))\nidxmissing[idxmiss] &lt;- 1\n\nDS$logP_ACD[which(DS$ID %in% idxmiss)] &lt;- 0\n\nlambda[which(lambda&gt;0.999)]=0.999\nlambda[which(lambda&lt;0.001)]=0.001\n\n\n\n\nCode\nlogP=DS$logP_ACD[!duplicated(DS$ID)]\nnObs=length(DS$ID)\nanalyte=DS$ID\nlogkObs=DS$logk\nfi=DS$concentration\nfiplot=seq(0,1,0.1)\nnfiplot=length(fiplot)\nrun_estimation=1\n\n# data to model\ndatastruct_prior = with(DS,\n                    list(logP=DS$logP_ACD[!duplicated(DS$ID)],\n                       idxmissing=idxmissing,\n                       nAnalytes=nAnalytes,\n                       nObs=nObs,\n                       analyte=DS$ID,\n                       logkObs=DS$logk, \n                       fi=DS$concentration,\n                       rawlambdai=1-lambda,\n                       nfiplot=length(fi),\n                       fiplot=fi,\n                       run_estimation=0))\n\ndatastruct = with(DS,\n                  list(logP=DS$logP_ACD[!duplicated(DS$ID)],\n                       idxmissing=idxmissing,\n                       nAnalytes=nAnalytes,\n                       nObs=nObs,\n                       analyte=DS$ID,\n                       logkObs=DS$logk, \n                       fi=DS$concentration,\n                       rawlambdai=1-lambda,\n                       nfiplot=length(fi),\n                       fiplot=fi,\n                       run_estimation=1))\n\n# declaring initial values for each variable in chains\ninit &lt;- function(){\n  list(logkwHat  = sort(c(rnorm(1,2,0.2),rnorm(1,2,0.2)+max(0,rnorm(1,2,0.5)))),\n       logkaHat  = sort(c(rnorm(1,-4,0.2),rnorm(1,-4,0.2)+max(0,rnorm(1,2,0.5)))),\n       logS2AHat = rnorm(2,log(2),0.2),\n       \n       omega1= c(1,1,0.1)*exp(rnorm(3,0,0.2)),\n       rho1 = diag(1,3,3),\n       omega2= c(1,1,0.1)*exp(rnorm(3,0,0.2)),\n       rho2 = diag(1,3,3),\n       \n       beta = c(0.7,0.7,0.5,0.5,0,0)*exp(rnorm(6,0,0.2)),\n       \n       param1 = Parameters_basic_fit[,3:5]*0.9,\n       param2 = Parameters_basic_fit[,3:5]*1.1,\n       sigma  = rlnorm(1,log(0.1),0.2)\n  )\n}\n\n# specifying parameters to analysis \nparametersToPlot &lt;- c(\"logkwHat\",\"logkaHat\",\"logS2AHat\",\"omega1\",\"rho1\",\"omega2\",\"rho2\",\"beta\",\n                      \"param1\",\"param2\",\"sigma\",\"logPmissing\")\notherRVs &lt;- c(\"logkCond\",\"logkPlotACond\",\"fracPred\",\"log_lik\",\"logkwPred\",\"logkaPred\",\"logS2APred\",\n              \"logkHat\",\"paramPred1\",\"paramPred2\",\"logkw\",\"logka\",\"logS2A\",\"logkHatPred\",\"log_likPred\")\n\nparameters &lt;- c(parametersToPlot, otherRVs)\nparametersToPlot &lt;- c(\"lp__\", parametersToPlot)\n\n# fitting model\nfit_prior &lt;- stan(file=\"ACN002.stan\",\n            data=datastruct_prior,\n            pars=parameters,\n            iter=2000,\n            warmup=1000,\n            init=init,\n            chains=4,thin=1,control = list(adapt_delta = 0.9,max_treedepth=15))\n\nfit &lt;- stan(file=\"ACN002.stan\",\n                   data=datastruct,\n                   pars=parameters,\n                   iter=2000,\n                   warmup=1000,\n                   init=init,\n                   chains=4,thin=1,control = list(max_treedepth=12))\n\n\nBelow code preapering data to fit the model in supercomputer:\n\n\nCode\nlogP=DS$logP_ACD[!duplicated(DS$ID)]\nnAnalytes=length(unique(DS$ID))\nnObs=length(DS$ID)\nanalyte=DS$ID\nlogkObs=DS$logk\nfi=DS$concentration\nfiplot=seq(0,1,0.1)\nnfiplot=length(fiplot)\nrun_estimation=1\n\nstan_rdump(c(\"logP\",\n             \"nAnalytes\", \n             \"nObs\",\n             \"idxmissing\", \n             \"analyte\", \n             \"logkObs\", \n             \"fi\",\n             \"rawlambdai\",\n             \"nfiplot\",\n             \"fiplot\",\n             \"run_estimation\"),\n           file=\"4_model_2/model.data.R\")\n\n\nWarning in stan_rdump(c(\"logP\", \"nAnalytes\", \"nObs\", \"idxmissing\", \"analyte\", :\nobjects not found: rawlambdai\n\n\nCode\nfor(i in 1:10){\n  logkwHat  = sort(c(rnorm(1,2,0.2),rnorm(1,2,0.2)+max(0,rnorm(1,2,0.5))))\n  logkaHat  = sort(c(rnorm(1,-4,0.2),rnorm(1,-4,0.2)+max(0,rnorm(1,2,0.5))))\n  logS2AHat = rnorm(2,log(2),0.2)\n  omega1= c(1,1,0.1)*exp(rnorm(3,0,0.2))\n  rho1 = diag(1,3,3)\n  omega2= c(1,1,0.1)*exp(rnorm(3,0,0.2))\n  rho2 = diag(1,3,3)\n  beta = c(0.7,0.7,0.5,0.5,0,0)*exp(rnorm(6,0,0.2))\n  param1 = Parameters_basic_fit[,3:5]*0.9\n  param2 = Parameters_basic_fit[,3:5]*1.1\n  sigma  = rlnorm(1,log(0.1),0.2)\n  \n  stan_rdump(c(\"logkwHat\",\"logkaHat\",\"logS2AHat\",\"beta\",\"rho1\",\"rho2\",\"omega1\",\"omega2\",\"param1\",\"param2\",\"sigma\"),\n             file=paste(\"4_model_2/model_\", i, \".init.R\", sep=\"\"))\n}"
  },
  {
    "objectID": "model_2.html#summary-of-model-parameters",
    "href": "model_2.html#summary-of-model-parameters",
    "title": "",
    "section": "Summary of model parameters",
    "text": "Summary of model parameters\nCode for print summary of parameters from supercomputer:\n\n\nCode\nfit &lt;- cmdstanr::as_cmdstan_fit(c('4_model_2/output_1.csv',\n                                  '4_model_2/output_2.csv',\n                                  '4_model_2/output_3.csv',\n                                  '4_model_2/output_4.csv',\n                                  '4_model_2/output_5.csv',\n                                  '4_model_2/output_6.csv',\n                                  '4_model_2/output_7.csv',\n                                  '4_model_2/output_8.csv',\n                                  '4_model_2/output_9.csv',\n                                  '4_model_2/output_10.csv'))\n\nfit$print(c(\"logkwHat\",\"logkaHat\",\"logS2AHat\",\"beta\",\"rho1\",\"rho2\",\"omega1\",\"omega2\",\"param1\",\"param2\",\"sigma\"), max_rows = 26)\n\n\nCode for print summary of parameters from computer:\n\n\nCode\nload(\"4_model_2/Fit.Rsave\")\nload(\"4_model_2/Fit_sample.Rsave\")\n\nprint(fit,pars=c(\"logkwHat\",\"logkaHat\",\"logS2AHat\",\"beta\",\"rho1\",\"rho2\",\"omega1\",\"omega2\",\"sigma\"))\n\n\nInference for Stan model: ACN0021_10_09.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n              mean se_mean   sd  2.5%   25%   50%   75% 97.5% n_eff Rhat\nlogkwHat[1]   1.13       0 0.14  0.86  1.03  1.13  1.21  1.40   962 1.00\nlogkwHat[2]   2.57       0 0.12  2.33  2.49  2.57  2.65  2.81  1971 1.00\nlogkaHat[1]  -2.95       0 0.11 -3.18 -3.02 -2.95 -2.87 -2.73   616 1.00\nlogkaHat[2]  -1.21       0 0.03 -1.27 -1.23 -1.21 -1.19 -1.15  2136 1.00\nlogS2AHat[1]  0.46       0 0.03  0.41  0.44  0.46  0.48  0.51   590 1.00\nlogS2AHat[2]  0.61       0 0.02  0.58  0.60  0.61  0.62  0.64  1534 1.00\nbeta[1]       0.87       0 0.05  0.78  0.83  0.87  0.90  0.96   783 1.01\nbeta[2]       0.85       0 0.04  0.76  0.82  0.85  0.87  0.93  1102 1.00\nbeta[3]       0.25       0 0.03  0.18  0.23  0.25  0.27  0.32   610 1.00\nbeta[4]       0.20       0 0.01  0.18  0.20  0.20  0.21  0.22  2352 1.00\nbeta[5]      -0.01       0 0.01 -0.03 -0.02 -0.01 -0.01  0.00   615 1.00\nbeta[6]      -0.05       0 0.01 -0.06 -0.05 -0.05 -0.04 -0.04  1031 1.00\nrho1[1,1]     1.00     NaN 0.00  1.00  1.00  1.00  1.00  1.00   NaN  NaN\nrho1[1,2]     0.44       0 0.05  0.34  0.41  0.44  0.48  0.54   432 1.03\nrho1[1,3]     0.43       0 0.05  0.33  0.39  0.43  0.46  0.52   594 1.01\nrho1[2,1]     0.44       0 0.05  0.34  0.41  0.44  0.48  0.54   432 1.03\nrho1[2,2]     1.00       0 0.00  1.00  1.00  1.00  1.00  1.00  3366 1.00\nrho1[2,3]     0.62       0 0.04  0.53  0.59  0.62  0.64  0.69   519 1.02\nrho1[3,1]     0.43       0 0.05  0.33  0.39  0.43  0.46  0.52   594 1.01\nrho1[3,2]     0.62       0 0.04  0.53  0.59  0.62  0.64  0.69   519 1.02\nrho1[3,3]     1.00       0 0.00  1.00  1.00  1.00  1.00  1.00   159 1.00\nrho2[1,1]     1.00     NaN 0.00  1.00  1.00  1.00  1.00  1.00   NaN  NaN\nrho2[1,2]     0.32       0 0.05  0.23  0.29  0.32  0.35  0.41  1313 1.00\nrho2[1,3]     0.39       0 0.05  0.29  0.35  0.39  0.42  0.48   786 1.00\nrho2[2,1]     0.32       0 0.05  0.23  0.29  0.32  0.35  0.41  1313 1.00\nrho2[2,2]     1.00       0 0.00  1.00  1.00  1.00  1.00  1.00  3333 1.00\nrho2[2,3]    -0.21       0 0.05 -0.31 -0.24 -0.21 -0.17 -0.10   844 1.01\nrho2[3,1]     0.39       0 0.05  0.29  0.35  0.39  0.42  0.48   786 1.00\nrho2[3,2]    -0.21       0 0.05 -0.31 -0.24 -0.21 -0.17 -0.10   844 1.01\nrho2[3,3]     1.00       0 0.00  1.00  1.00  1.00  1.00  1.00  2528 1.00\nomega1[1]     1.31       0 0.07  1.17  1.26  1.30  1.35  1.46   490 1.00\nomega1[2]     1.01       0 0.05  0.92  0.98  1.01  1.04  1.11   475 1.01\nomega1[3]     0.23       0 0.01  0.20  0.22  0.23  0.24  0.25   479 1.01\nomega2[1]     1.50       0 0.07  1.37  1.45  1.50  1.54  1.64   676 1.00\nomega2[2]     0.36       0 0.02  0.32  0.34  0.36  0.37  0.39   678 1.01\nomega2[3]     0.18       0 0.01  0.17  0.18  0.18  0.19  0.20   838 1.00\nsigma         0.03       0 0.00  0.03  0.03  0.03  0.03  0.03   745 1.01\n\nSamples were drawn using NUTS(diag_e) at Mon Nov 09 13:55:42 2020.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1)."
  },
  {
    "objectID": "model_2.html#goodness-of-fit",
    "href": "model_2.html#goodness-of-fit",
    "title": "",
    "section": "Goodness of fit",
    "text": "Goodness of fit\n\n\nCode\nlibrary(metRology) # function rt.scaled\n\nlogkPred &lt;-array(rep(5097*4000),dim=c(4000,5097))\nfor(j in 1:nObs){\n  for(k in 1:4000){\n    logkPred[k,j]       = rt.scaled(1,7,fit_sample$logkHatPred[k,j], fit_sample$sigma[k])\n  }\n}\n\npar(mfrow=c(1,2))\nplot(apply(fit_sample$logkCond,2,mean),DS$logk,cex.lab=1.2,xlim=c(-4,6),ylim=c(-3,3),pch=20,col=\"blue\",ylab=expression(\"Log k\"[Obs]),xlab=expression(\"Log k\"[Pred]))\nlines(seq(-4,6,by=0.1),seq(-4,6,by=0.1),lwd=2)\nplot(apply(logkPred,2,mean),DS$logk,cex.lab=1.2,xlim=c(-4,6),ylim=c(-3,3),pch=20,col=\"blue\",ylab=expression(\"Log k\"[Obs]),xlab=expression(\"Log k\"[Pred]))\nlines(seq(-4,6,by=0.1),seq(-4,6,by=0.1),lwd=2)\n\n\n\n\n\n\nWAIC\n\n\nCode\nlibrary(loo)\nwaic(extract_log_lik(fit)) # to samo co: waic(fit_sample$log_lik)\n\n\nWarning: \n2211 (43.4%) p_waic estimates greater than 0.4. We recommend trying loo instead.\n\n\n\nComputed from 4000 by 5097 log-likelihood matrix\n\n          Estimate    SE\nelpd_waic   7660.0 219.5\np_waic      3635.8 203.4\nwaic      -15320.1 438.9\n\n2211 (43.4%) p_waic estimates greater than 0.4. We recommend trying loo instead. \n\n\nCode\nloo(extract_log_lik(fit))\n\n\nWarning: Relative effective sample sizes ('r_eff' argument) not specified.\nFor models fit with MCMC, the reported PSIS effective sample sizes and \nMCSE estimates will be over-optimistic.\n\n\nWarning: Some Pareto k diagnostic values are too high. See help('pareto-k-diagnostic') for details.\n\n\n\nComputed from 4000 by 5097 log-likelihood matrix\n\n         Estimate    SE\nelpd_loo   7325.4 122.8\np_loo      3970.5  95.5\nlooic    -14650.8 245.7\n------\nMonte Carlo SE of elpd_loo is NA.\n\nPareto k diagnostic values:\n                         Count Pct.    Min. n_eff\n(-Inf, 0.5]   (good)     2863  56.2%   77        \n (0.5, 0.7]   (ok)        987  19.4%   50        \n   (0.7, 1]   (bad)       917  18.0%   12        \n   (1, Inf)   (very bad)  330   6.5%   2         \nSee help('pareto-k-diagnostic') for details."
  },
  {
    "objectID": "model_2.html#predictions",
    "href": "model_2.html#predictions",
    "title": "",
    "section": "Predictions",
    "text": "Predictions\nIndividual predictions\n\n\nCode\nlibrary(ggpubr)\n\nnazwy &lt;- c(\"Caffeine\",\"Chlorpropamide\",\"Doxepin hydrochloride\",\"Perphenazine\",\n  \"Pindolol\",\"Phenylbutazone\",\"Procainamide hydrochloride\",\"Retinoic acid\",\n  \"Sulfaphenazole\",\"Tolbutamide\",\"Ketoprofen\",\"Indomethacin\")\nl_nazwy &lt;- which(DS_names$Analyte[!duplicated(DS_names$ID)] %in% nazwy)\n\nplots &lt;- list()\nfor(i in 1:nAnalytes){\n  l &lt;- apply(drop(fit_sample$logkPlotACond[,i,]), MARGIN = 2, FUN = quantile, probs = c(.025,.5,.975))\n  logk_prct &lt;- as.data.frame(cbind(rep(i,11),fiplot,t(l)))\n  colnames(logk_prct)&lt;-c(\"ID\",\"concentration\",\"low\",\"median\",\"high\")\n  plots[[i]] &lt;- ggplot()+ xlim(0,1) +\n    geom_point(data=subset(DS, ID == i), aes(x = concentration, y = logk), col=\"blue\") +\n    geom_line(data=subset(logk_prct, ID == i), aes(x = fiplot, y = median), col=\"blue\") +\n    geom_ribbon(data=subset(logk_prct, ID == i), aes(x = fiplot, \n                                                     ymin = low, \n                                                     ymax = high), alpha = 0.25, fill=\"blue\")+\n    coord_cartesian(ylim = c(-3, 4)) + \n    labs(title = paste(DS$Names[which(DS$ID==i)]),\n         x = NULL,\n         y = NULL) +\n    theme(text = element_text(size = 9), axis.text = element_text(size = 9),\n          legend.position = \"none\", strip.text = element_text(size = 6)) \n}\nfigure1 &lt;- ggarrange(plotlist = plots[l_nazwy], nrow=3,ncol = 4)\nannotate_figure(figure1,\n                bottom = text_grob(expression(varphi)),\n                left = text_grob(\"log k\", rot = 90))\n\n\n\n\n\nPopulation predictions\n\n\nCode\nhplc &lt;- function(fi,logkw,logka,logS2A){\n  S1 = (logkw - logka)*(1+10^logS2A)\n  logk = logkw - S1 * fi / (1 + 10^logS2A * fi)\n  return(logk)\n}\n\nlogkHatPlotAPred &lt;-array(rep(0,11*1026*8000),dim=c(8000,1026,11))\nlogkPlotAPred &lt;-array(rep(0,11*1026*8000),dim=c(8000,1026,11))\n\nfor(j in 1:nAnalytes){\n  for(z in 1:nfiplot){\n    for(k in 1:8000){\n      logkHatPlotAPred[k,j,z]   = hplc(fiplot[z], fit_sample$logkwPred[k,j],\n                                   fit_sample$logkaPred[k,j], fit_sample$logS2APred[k,j])\n      logkPlotAPred[k,j,z]      = rt.scaled(1,7,logkHatPlotAPred[k,j,z], fit_sample$sigma[k])\n    }\n  }\n}\nsave(logkPlotAPred,\"4_model_2/logkPlotAPred.Rsave\")\n\n\n\n\nCode\nload(\"4_model_2/logkPlotAPred.Rsave\")\n\nplots &lt;- list()\nfor(i in 1:nAnalytes){\n  l &lt;- apply(drop(logkPlotAPred[,i,]), MARGIN = 2, FUN = quantile, probs = c(.025,.5,.975))\n  logk_prct &lt;- as.data.frame(cbind(rep(i,11),fiplot,t(l)))\n  colnames(logk_prct)&lt;-c(\"ID\",\"concentration\",\"low\",\"median\",\"high\")\n  plots[[i]] &lt;- ggplot()+ xlim(0,1) +\n    geom_point(data=subset(DS, ID == i), aes(x = concentration, y = logk), col=\"blue\") +\n    geom_line(data=subset(logk_prct, ID == i), aes(x = fiplot, y = median), col=\"red\") +\n    geom_ribbon(data=subset(logk_prct, ID == i), aes(x = fiplot, \n                                                     ymin = low, \n                                                     ymax = high), alpha = 0.25, fill=\"red\")+\n    coord_cartesian(ylim = c(-3, 4)) + \n    labs(title = paste(DS$Names[which(DS$ID==i)]),\n         x = NULL,\n         y = NULL) +\n    theme(text = element_text(size = 9), axis.text = element_text(size = 9),\n          legend.position = \"none\", strip.text = element_text(size = 6)) \n}\nfigure1 &lt;- ggarrange(plotlist = plots[l_nazwy], nrow=3,ncol = 4)\nannotate_figure(figure1,\n                bottom = text_grob(expression(varphi)),\n                left = text_grob(\"log k\", rot = 90))\n\n\n\n\n\n\nUncertainty chromatograms\nPlot uncertainity chromatograms expected isocratically at fi=0.5 for 7 randomly selected analytes\n\n\nCode\nlibrary(reshape2)\nanalyte_ID_sample &lt;- c(122,370,412,626,650,719,772)\ndata_to_plot &lt;- logkPlotAPred[,which(DS_names$ID %in% analyte_ID_sample),which(fiplot==0.5)]\ncolnames(data_to_plot) &lt;- paste(DS_names$Analyte[analyte_ID_sample])\n\nwp &lt;- melt(data_to_plot)\np &lt;- ggplot(aes(x=value, colour=Var2), data=wp)\np + geom_density() + xlim(c(-3,3)) + xlab(\"Logarithm retention factor\") + guides(colour=guide_legend(title=\"Compouds\"))\n\n\n\n\n\nPlot uncertainity chromatograms expected for a typical gradient for 7 randomly selected analytes\n\n\nCode\nhplcmodelgra &lt;- function(logkw,logka,logS2A,tg,fio,fif,to,td,te,time){\n  fi = fio - (fio-fif)/tg*(time-td)\n  fi[which(time&lt;td)] = fio\n  fi[which(time&gt;tg+td)] = fif\n  S1 = (logkw - logka)*(1+10^logS2A)\n  tr &lt;- matrix(NA,nrow(logkw),ncol(logkw))\n  for(i in 1:nrow(logkw)){\n    for(j in 1:ncol(logkw)){\n      logki = logkw[i,j] - S1[i,j]*fi/(1 + 10^logS2A[i,j]*fi)\n      ki = 10^logki\n      inv_k_i = 1/to/ki\n      cumtr  = cumtrapz(time,inv_k_i)\n      if(cumtr[length(cumtr)]&gt;=1){\n        trprim = interp1(as.vector(cumtr),time,1)\n      }else{\n          trprim = (1-cumtr[length(cumtr)])*ki[length(ki)]*to+time[length(time)]\n      }\n      tr[i,j] = trprim + to + te\n    }\n  }\n  return(tr)\n}\n\n\n\n\nCode\ndata_to_plot &lt;- hplcmodelgra(fit_sample$logkwPred[,analyte_ID_sample],\n                             fit_sample$logkaPred[,analyte_ID_sample],\n                             fit_sample$logS2APred[,analyte_ID_sample],\n                             20,0,1,1,0.2,0,seq(0,20+10,length.out=1000))\ncolnames(data_to_plot) &lt;- paste(DS_names$Analyte[analyte_ID_sample])\n\nwp &lt;- melt(data_to_plot)\np &lt;- ggplot(aes(x=value, colour=Var2), data=wp)\np + geom_density() + xlim(c(0,30)) + xlab(\"Retention time\") +\n  guides(colour=guide_legend(title=\"Compouds\"))\n\n\n\n\n\n\n\nCode\nanalyte_ID_sample &lt;- c(112, 122, 241, 379,498, 512, 626, 672, 726, 772)\ndata_to_plot &lt;- hplcmodelgra(fit_sample$logkwPred[,analyte_ID_sample],\n                             fit_sample$logkaPred[,analyte_ID_sample],\n                             fit_sample$logS2APred[,analyte_ID_sample],\n                             20,0,1,1,0.2,0,seq(0,20+10,length.out=1000))\ncolnames(data_to_plot) &lt;- paste(DS_names$Analyte[analyte_ID_sample])\n\nwp &lt;- melt(data_to_plot)\np &lt;- ggplot(aes(x=value, colour=Var2), data=wp)\np + geom_density() + xlim(c(0,30)) + xlab(\"Retention time\") + guides(colour=guide_legend(title=\"Compouds\"))"
  },
  {
    "objectID": "methods.html",
    "href": "methods.html",
    "title": "",
    "section": "",
    "text": "Code\n\n\n\n\nMethods\nDescribed models assume a nonlinear relationship between \\(\\log k\\) and the content of organic modifier \\(\\varphi\\) (Neue et al.  equation): \\[\\begin{align*}\n\\log k =\\log k_w - \\frac{S_1 \\cdot \\varphi}{1+S_2 \\cdot \\varphi} , \\label{Neue}\n\\end{align*}\\] where \\(\\log k_w\\) stands for the logarithm of the retention factor corresponding to neat water as the eluent, and \\(S_1\\), \\(S_2\\) are constants describing the steepness of the relationship between the solvent composition and the logarithm of the retention factor. We also assumed that: \\[\\begin{align*}\nS_1 &= (\\log k_w - \\log k_a ) \\cdot ( 1+ 10^{\\log S_{2}} )\n\\end{align*}\\] where \\(\\log k_a\\) denotes the logarithm of the retention factor in 100% acetonitrile and \\(\\log S_{2}\\) denotes the logarithm of the curvature coefficient.\nThe first levels of our hierarchical models have the following form: \\[\\begin{align*}\n\\log k_{Obs_{i,j}} \\sim N(f(R_i,\\varphi_{i,j}),\\sigma)\n\\end{align*}\\] where \\(R_i=(\\log k_{w_i}, \\log k_{a_i}, \\log S_{2_i})\\) is a vector of analyte-specific chromatographic parameters, \\(f\\) is a function corresponding to the right side of the Neue equation and \\(\\sigma\\) is the standard deviation."
  },
  {
    "objectID": "packages.html",
    "href": "packages.html",
    "title": "",
    "section": "",
    "text": "CodeShow All CodeHide All CodeView Source\n\n\n\n\nSetup\nPackages:\n\n\nCode\nlibrary(pracma)\nlibrary(dplyr)\nlibrary(ggplot2)\nrequire(gridExtra)\nlibrary(cmdstanr)\nlibrary(rstan)\nlibrary(knitr)\nlibrary(reshape2)\nlibrary(bayesplot)\nlibrary(posterior)\nlibrary(GGally)\nlibrary(kableExtra)\nlibrary(here)\n\nset.seed(10271998) ## not required but assures repeatable results"
  }
]