[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistical analysis of isocratic chromatographic data using Bayesian modeling",
    "section": "",
    "text": "Introduction\nPrediction of retention times is difficult due to the complexity and multiplicity of various interactions that occur during separation in an RP-HPLC column. The most important of these are the interactions between the analytes, between the solvent and the analytes, and the interactions of the stationary phase constituents with each other, as well as with the molecules of analytes and solvents.\nIn this work, we decided to use Bayesian hierarchical models. This models contain two types of parameters: population-level parameters (fixed effect) and individual-level parameters (random effect). The fixed effects are the parameters of the population which are immutable for each data collected from the population. In contrast, the random effects are those parameters whose values differ for individual representatives of the population (i.e., each analyte). As for the regression models, their purpose is to describe the response variable as a function of predictor variables. However, the advantage of multilevel models is the recognition of similarity between the analytes which provides more information about the retention of individual analytes, due to the fact that the missing information can be borrowed from other similar analytes."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This page contains an analysis of isocratic chromatographic data published in the article:\nAgnieszka Kamedulska, Łukasz Kubik, Paweł Wiczling, 2022, “Statistical analysis of isocratic chromatographic data using Bayesian modeling”, Analytical and Bioanalytical Chemistry, 414 (11): 3471-3481."
  },
  {
    "objectID": "packages.html",
    "href": "packages.html",
    "title": "izo_1026_logP",
    "section": "",
    "text": "Setup\nPackages:\n\n\nCode\nlibrary(pracma)\nlibrary(dplyr)\nlibrary(ggplot2)\nrequire(gridExtra)\nlibrary(cmdstanr)\nlibrary(rstan)\nlibrary(knitr)\nlibrary(reshape2)\nlibrary(bayesplot)\nlibrary(posterior)\nlibrary(GGally)\nlibrary(kableExtra)\nlibrary(here)\n\nset.seed(10271998) ## not required but assures repeatable results"
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "",
    "section": "",
    "text": "CodeShow All CodeHide All CodeView Source\n\n\n\n\nData\nWe used a publicly available dataset that comprises the measurements of RP-HPLC retention times collected for 1026 analytes. The retention times were measured under isocratic conditions on Eclipse Plus C18 (Agilent) stationary phase with 3.5 μm particles. The experiments were conducted using a mixture of two solvents: solvent A, which was made of 0.1% formic acid in water, and solvent B, which was made of 0.1% formic acid in acetonitrile. The column temperature was set at 35^{}C. The data were collected by Boswell et al. and were used to create a method to predict retention time by Back-Calculating the Gradient.\n\n\nCode\n# load packages\nlibrary(here)\nlibrary(ggplot2)\n\n# load data\nDS       &lt;- read.csv(here::here(\"1_data/database_stan_1026.csv\"),header = TRUE, sep = \";\", dec = \".\")\nDS_names &lt;- read.csv(here::here(\"1_data/database_stan_1026_analyte_names.csv\"),header = TRUE, sep = \",\", dec = \".\")\nDS_pKa   &lt;- read.csv(here::here(\"1_data/ACD_pKas.csv\"),header = TRUE, sep = \",\", dec = \".\")\n\n# divide the analytes into groups according to log P\nDS$logP_group &lt;- with(DS, ifelse(logP_ACD &lt; 1.5, \"1\",\n                                 ifelse(logP_ACD &lt; 3 & logP_ACD &gt;= 1.5, \"2\", \n                                        ifelse(logP_ACD &lt; 4.5 & logP_ACD &gt;= 3, \"3\", \"4\" ))))\nlab &lt;- function(x){\n  ifelse(x == 1, \"log P &lt; 1.5\",\n         ifelse(x == 2, \"1.5 \\u2264 log P &lt; 3\", \n                ifelse(x == 3, \"3 \\u2264 logP &lt; 4.5\", \"4.5 \\u2264 log P\" )))\n}\n\nnObs &lt;- length(DS$ID)\nnAnalytes &lt;- length(unique(DS$ID))\nfi &lt;- seq(0,1,0.1)\n\nggplot(data=DS, aes(x=concentration, y=logk, group=ID)) + \n  geom_line(aes(color=ID)) + \n  facet_wrap(~logP_group, ncol=2, labeller=labeller(logP_group = lab)) +\n  labs(x = expression(varphi), y = expression(Log~k[Obs])) + \n  theme_gray(base_size = 14) + theme(legend.position=\"none\") \n\n\n\n\n\nThe pH value of the mobile phase was verified experimentally for the purpose of this work. It equaled 2.66 with a standard deviation of 0.19 for the range of acetonitrile contents from 5 to 95%.\n\n\nCode\nDS_pH &lt;- read.csv(here::here(\"1_data/pH.csv\"),header = TRUE, sep = \";\", dec = \",\")\n\n\nggplot(data=DS_pH, aes(x=fi, y=pH)) + labs(x = expression(varphi), y = \"pH\") + \n  geom_point() + geom_hline(yintercept=mean(DS_pH$pH), color = \"red\") +\n  geom_hline(yintercept=mean(DS_pH$pH)-sd(DS_pH$pH), linetype=\"dashed\", color = \"red\") +\n  geom_hline(yintercept=mean(DS_pH$pH)+sd(DS_pH$pH), linetype=\"dashed\", color = \"red\") + ylim(c(2.0,3.5))\n\n\n\n\n\nThe values of lipophilicity log P, molecular mass MM, and pKa were added to the dataset. They were calculated using ACD/Labs program based on the provided structures of analytes. The log P value of the analytes ranged from −5 to 8.75, and MM ranged from 73.09 to 656.8.\n\n\nCode\nlibrary(tidyverse)\n\ndf &lt;- DS %&gt;% distinct(ID,logP_ACD,MW_ACD) %&gt;%\n  gather(c(logP_ACD,MW_ACD), key= ACD, value=\"value\") %&gt;%\n  mutate(ACD = recode(ACD, \"logP_ACD\" = \"log P\", \"MW_ACD\" = \"MM\"))\n\nggplot(data= df , aes(x=ACD, y=value))+\n  geom_boxplot(aes(1))+facet_wrap(~ ACD,scales = \"free\") +\n  theme(axis.title.x=element_blank(),\n        axis.text.x=element_blank(),\n        axis.ticks.x=element_blank())\n\n\n\n\n\nThe pKa values was ranged from −21.40 to 19.14. For one analyte (diphenyleneiodonium chloride), ACD/Labs program could not calculate the log P value, and therefore, this value was treated as missing, which was modeled assuming that log P of that analyte comes from the normal distribution with location 2.56 and scale 1.92, which are the mean and standard deviation of log P data for other analytes."
  },
  {
    "objectID": "methods.html",
    "href": "methods.html",
    "title": "",
    "section": "",
    "text": "Code\n\n\n\n\nMethods\nDescribed models assume a nonlinear relationship between \\(\\log k\\) and the content of organic modifier \\(\\varphi\\) (Neue et al.  equation): \\[\\begin{align*}\n\\log k =\\log k_w - \\frac{S_1 \\cdot \\varphi}{1+S_2 \\cdot \\varphi} , \\label{Neue}\n\\end{align*}\\] where \\(\\log k_w\\) stands for the logarithm of the retention factor corresponding to neat water as the eluent, and \\(S_1\\), \\(S_2\\) are constants describing the steepness of the relationship between the solvent composition and the logarithm of the retention factor. We also assumed that: \\[\\begin{align*}\nS_1 &= (\\log k_w - \\log k_a ) \\cdot ( 1+ 10^{\\log S_{2}} )\n\\end{align*}\\] where \\(\\log k_a\\) denotes the logarithm of the retention factor in 100% acetonitrile and \\(\\log S_{2}\\) denotes the logarithm of the curvature coefficient.\nThe first levels of our hierarchical models have the following form: \\[\\begin{align*}\n\\log k_{Obs_{i,j}} \\sim N(f(R_i,\\varphi_{i,j}),\\sigma)\n\\end{align*}\\] where \\(R_i=(\\log k_{w_i}, \\log k_{a_i}, \\log S_{2_i})\\) is a vector of analyte-specific chromatographic parameters, \\(f\\) is a function corresponding to the right side of the Neue equation and \\(\\sigma\\) is the standard deviation."
  },
  {
    "objectID": "initial_model.html",
    "href": "initial_model.html",
    "title": "",
    "section": "",
    "text": "CodeShow All CodeHide All CodeView Source"
  },
  {
    "objectID": "initial_model.html#priors",
    "href": "initial_model.html#priors",
    "title": "",
    "section": "Priors",
    "text": "Priors\nIn this work were used weakly uninformative priors as described in our previous work (Kubik, Kaliszan, and Wiczling 2018): \\[\\begin{align*}\n\\nu \\sim Gamma(2,0.1),\\\\\n\\theta_{\\log k_{w}} \\sim N(2,5),  \\quad \\theta_{\\log k_{a}} \\sim N(0,5),\\\\\n\\theta_{\\log S_{2}},  \\sim N(\\log 2,0.5), \\\\\n\\beta_{\\log k_{w}} \\sim N(1,0.5), \\quad\n\\beta_{\\log k_{a}} \\sim N(1,0.5), \\\\\n\\text{logPmissing} \\sim N(2.56,1.92), \\\\\n\\omega \\sim N(0,5),\\\\\n\\begin{bmatrix}\n1 & \\rho_{1,2} & \\rho_{1,3} \\\\\n\\rho_{2,1} & 1 & \\rho_{2,3} \\\\\n\\rho_{3,1} & \\rho_{3,2} & 1\n\\end{bmatrix} \\sim LKJ(1), \\\\\n\\sigma \\sim N(0,1),\\\\\n\\eta \\sim MST(\\nu,\\theta_{\\eta},\\Omega).\n\\end{align*}\\]"
  },
  {
    "objectID": "initial_model.html#analysis",
    "href": "initial_model.html#analysis",
    "title": "",
    "section": "Analysis",
    "text": "Analysis\nAt the beginning, a model was constructed and implemented in the Stan program.\n\n\nCode\nfunctions{\n  real hplcmodel(real fi, real logkw, real logka, real logS2A){\n    \n    real logk;                                              // retention factor\n    real S1;                                                // slope coefficient\n    \n    S1 = (logkw - logka)*(1+exp(logS2A));\n    logk                    = logkw - S1 * fi / (1 + exp(logS2A) * fi);\n    \n    return logk;\n  }\n}\ndata{\n  int nAnalytes;                                            // number of analytes\n  int nObs;                                             // number of observations\n  int analyte[nObs];                                        // analytes indexes\n  vector[nObs] logkObs;                                 // observed retention factors\n  vector[nObs] fi;                                      // organic modifier content in the mobile phase\n  real logP[nAnalytes];      \n  int idxmissing[nAnalytes];\n  int nfiplot;                                          // number of fi for plotting\n  vector[nfiplot] fiplot;                                   // organic modifier content in the mobile phase\n  \n  int&lt;lower = 0, upper = 1&gt; run_estimation; // 0 for prior predictive, 1 for estimation\n}\n\ntransformed data{\n  vector[3] etaHat;\n  etaHat                    = rep_vector(0.0,3);\n}\n\nparameters{\n  real logkaHat;                                           // retention factor in acetonitrile for  analyte with MLOGP 0\n  real logS2AHat;                                          // mean curvature coefficient for acetonitrile in population\n  real&lt;lower = 0&gt; sigmaadd;                            // standard deviation for residuals\n  corr_matrix[3] rho;                                      // correlation matrix\n  vector&lt;lower = 0&gt;[3] omega;                              // diagonal elements of variance-covariance matrix\n  real logkwHat;                                           // mean value of logkw in population\n  vector[3] eta[nAnalytes];                            // inter-individual variability\n  real beta_logkw;                                     // coefficient value for molecular descriptor\n  real beta_logka;\n  real nu;          // normality constant\n  real logPmissing[nAnalytes];\n}\n\ntransformed parameters{\n  cov_matrix[3] Omega;                                  // variance-covariance matrix\n  real logka[nAnalytes];                                    // slope coefficient for acetonitrile\n  real logS2A[nAnalytes];                                   // curvature coefficient for acetonitrile\n  real logkw[nAnalytes];                                    // retention factor in neat water\n  vector[nObs] logkHat;                                 // mean value of logk in population\n  \n  Omega = quad_form_diag(rho, omega);   // diag_matrix(omega) * rho * diag_matrix(omega)\n  \n  for(j in 1:nAnalytes){\n    logka[j]  = eta[j, 1] + logkaHat + beta_logka * ((1-idxmissing[j])*logP[j]+idxmissing[j]*logPmissing[j]);\n    logS2A[j] = eta[j, 2] + logS2AHat;\n    logkw[j]  = eta[j, 3] + logkwHat + beta_logkw * ((1-idxmissing[j])*logP[j]+idxmissing[j]*logPmissing[j]);\n  }\n  \n  for(i in 1:nObs){\n    logkHat[i] = hplcmodel(fi[i], logkw[analyte[i]], logka[analyte[i]], logS2A[analyte[i]]);\n  }\n}\n\nmodel{\n  logkwHat              ~ normal(2, 5);\n  logkaHat              ~ normal(0, 5);\n  logS2AHat             ~ normal(log(2), 0.5);\n    beta_logkw              ~ normal(1,0.5);\n    beta_logka              ~ normal(1,0.5);\n  logPmissing ~ normal(2.56,1.92);\n  omega                 ~ normal(0,5);\n  nu                      ~ gamma(2,0.1);\n  rho                       ~ lkj_corr(1);\n  sigmaadd              ~ normal(0,1);\n  eta                       ~ multi_student_t(nu,etaHat, Omega);    // inter-individual variability\n\n  if(run_estimation==1){\n  logkObs                   ~ normal(logkHat, sigmaadd);    // observations\n}\n\n}\n\ngenerated quantities{\n  \n  vector[3] etaPred[nAnalytes];                         // etas\n  real logkaPred[nAnalytes];                                // etention factor in acetonitrile\n  real logS2APred[nAnalytes];                               // curvature coefficient for acetonitrile\n  real logkwPred[nAnalytes];                                // retention factor in neat water\n  vector[nObs] logkHatPred;                             // predicted logk   \n  real logkCond[nObs];\n  real logkPred[nObs];\n  real log_lik[nObs];\n  real log_likPred[nObs];\n  matrix[nAnalytes,nfiplot] logkHatPlotACond;\n  matrix[nAnalytes,nfiplot] logkPlotACond;\n  matrix[nAnalytes,nfiplot] logkHatPlotAPred;\n  matrix[nAnalytes,nfiplot] logkPlotAPred;\n  \n  for(j in 1:nAnalytes){\n    etaPred[j] = multi_student_t_rng(nu,etaHat, Omega); // inter-individual variability\n    logkaPred[j] = etaPred[j, 1] + logkaHat + beta_logka * ((1-idxmissing[j])*logP[j]+idxmissing[j]*logPmissing[j]);\n    logS2APred[j]   = etaPred[j, 2] + logS2AHat;\n    logkwPred[j]    = etaPred[j, 3] + logkwHat + beta_logkw * ((1-idxmissing[j])*logP[j]+idxmissing[j]*logPmissing[j]);\n  }\n  \n  for(i in 1:nObs){\n    logkHatPred[i]  = hplcmodel(fi[i], logkwPred[analyte[i]], logkaPred[analyte[i]], logS2APred[analyte[i]]);\n    logkCond[i]     = normal_rng(logkHat[i], sigmaadd);\n    logkPred[i]     = normal_rng(logkHatPred[i], sigmaadd);\n    log_lik[i]      = normal_lpdf(logkObs[i] | logkHat[i], sigmaadd);\n    log_likPred[i]  = normal_lpdf(logkObs[i] | logkHatPred[i], sigmaadd);\n  }\n  \n  for(j in 1:nAnalytes){\n    for(z in 1:nfiplot){\n      logkHatPlotACond[j,z] = hplcmodel(fiplot[z], logkw[j], logka[j], logS2A[j]);\n      logkPlotACond[j,z]        = normal_rng(logkHatPlotACond[j,z], sigmaadd);\n      \n      logkHatPlotAPred[j,z] = hplcmodel(fiplot[z], logkwPred[j], logkaPred[j], logS2APred[j]);\n      logkPlotAPred[j,z]        = normal_rng(logkHatPlotAPred[j,z], sigmaadd);\n      \n    }\n  }\n  \n}\n\n\nThen, the data was added to it and the initial values of the model parameters were determined. In the end, the model was fitted.\n\n\nCode\n# indicating missing value of log P\nidxmissing &lt;- rep(0,1026)\nidxmiss &lt;- which(is.nan(DS$logP_ACD[!duplicated(DS$ID)]))\nidxmissing[idxmiss] &lt;- 1\n\nDS$logP_ACD[which(DS$ID %in% idxmiss)] &lt;- 0\n\n# data to model\ndatastruct_prior = with(DS,\n                    list(logP=DS$logP_ACD[!duplicated(DS$ID)],\n                       idxmissing=idxmissing,\n                       nAnalytes=nAnalytes,\n                       nObs=nObs,\n                       analyte=DS$ID,\n                       logkObs=DS$logk, \n                       fi=DS$concentration,\n                       nfiplot=length(fi),\n                       fiplot=fi,\n                       run_estimation=0))\n\ndatastruct = with(DS,\n                  list(logP=DS$logP_ACD[!duplicated(DS$ID)],\n                       idxmissing=idxmissing,\n                       nAnalytes=nAnalytes,\n                       nObs=nObs,\n                       analyte=DS$ID,\n                       logkObs=DS$logk, \n                       fi=DS$concentration,\n                       nfiplot=length(fi),\n                       fiplot=fi,\n                       run_estimation=1))\n\n# declaring initial values for each variable in chains\ninit &lt;- function(){\n  list(logkwHat  = mean(inital_param_A[,2]+rnorm(nAnalytes,0,0.5)),\n       logkaHat  = rnorm(1,0,0.5),\n       logS2AHat = log(2)+rnorm(1,0,0.5),\n       \n       beta_logka = 0.4+rnorm(1,0,0.1),\n       beta_logkw = 0.8+rnorm(1,0,0.1),\n       \n       eta= matrix(rnorm(nAnalytes*3,0,0.5),nAnalytes,3),\n       \n       rho = diag(1,3,3),\n       \n       nu = max(1, 10+rnorm(1,0,2)),\n       \n       omega= c(3,3,3)*exp(rnorm(3,0,0.2)),\n       sigmaadd = 0.2*exp(rnorm(1,0,0.2))\n  )\n}\n\n# specifying parameters to analysis \nparametersToPlot &lt;- c(\"logkwHat\",\"logkaHat\",\"logS2AHat\",\"beta_logka\",\"beta_logkw\",\"eta\",\"rho\",\"nu\",\"omega\",\"sigmaadd\")\notherRVs &lt;- c(\"logkCond\",\"logkPred\",\"logkPlotACond\",\"logkPlotAPred\",\"log_lik\",\"log_likPred\",\n              \"eta\",\"etaPred\")\n\nparameters &lt;- c(parametersToPlot, otherRVs)\nparametersToPlot &lt;- c(\"lp__\", parametersToPlot)\n\n# fitting model\nfit_prior &lt;- stan(file=\"HPLCizomodel44.stan\",\n            data=datastruct_prior,\n            pars=parameters,\n            iter=2000,\n            warmup=1000,\n            init=init,\n            chains=4,thin=1,control = list(adapt_delta = 0.9,max_treedepth=15))\n\nfit &lt;- stan(file=\"ACN000.stan\",\n                   data=datastruct,\n                   pars=parameters,\n                   iter=2000,\n                   warmup=1000,\n                   init=init,\n                   chains=4,thin=1,control = list(max_treedepth=12))\n\n\nBelow code preapering data to fit the model in supercomputer:\n\n\nCode\n# load packages\nlibrary(pracma)\nlibrary(dplyr)\nlibrary(ggplot2)\nrequire(gridExtra)\nlibrary(GGally)\nlibrary(cmdstanr)\nlibrary(rstan)\nlibrary(knitr)\nlibrary(reshape2)\nlibrary(bayesplot)\nlibrary(posterior)\n\n# load data\nDS       &lt;- read.csv(here::here(\"1_data/database_stan_1026.csv\"),header = TRUE, sep = \";\", dec = \".\")\nDS_names &lt;- read.csv(here::here(\"1_data/database_stan_1026_analyte_names.csv\"),header = TRUE, sep = \",\", dec = \".\")\nDS_pKa   &lt;- read.csv(here::here(\"1_data/ACD_pKas.csv\"),header = TRUE, sep = \",\", dec = \".\")\n\nidxmissing &lt;- rep(0,1026)\nidxmiss &lt;- which(is.nan(DS$logP_ACD[!duplicated(DS$ID)]))\nidxmissing[idxmiss] &lt;- 1\nDS$logP_ACD[which(DS$ID %in% idxmiss)] &lt;- 0\n\nlogP=DS$logP_ACD[!duplicated(DS$ID)]\nnAnalytes=length(unique(DS$ID))\nnObs=length(DS$ID)\nanalyte=DS$ID\nlogkObs=DS$logk\nfi=DS$concentration\nfiplot=seq(0,1,0.1)\nnfiplot=length(fiplot)\nrun_estimation=1\n\nstan_rdump(c(\"logP\",\n             \"nAnalytes\", \n             \"nObs\",\n             \"idxmissing\", \n             \"analyte\", \n             \"logkObs\", \n             \"fi\",\n             \"nfiplot\",\n             \"fiplot\",\n             \"run_estimation\"),\n           file=\"2_initial_model/model.data.R\")\n\ninital_param_A &lt;- matrix(NA,nAnalytes,2)\nfor(i in 1:nAnalytes){\n  inital_param_A[i,] = \n    polyfit(DS$concentration[which(DS$ID==i)]/(1+2*DS$concentration[which(DS$ID==i)]),\n            DS$logk[which(DS$ID==i)],1)\n}\n\nfor(i in 1:10){\n  logkwHat  =  mean(inital_param_A[,2]+rnorm(nAnalytes,0,0.5))\n  logkaHat  = rnorm(1,0,0.5)\n  logS2AHat = log(2)+rnorm(1,0,0.5)\n  beta_logka = 0.4+rnorm(1,0,0.1)\n  beta_logkw = 0.8+rnorm(1,0,0.1)\n  eta= matrix(rnorm(nAnalytes*3,0,0.5),nAnalytes,3)\n  rho = diag(1,3,3)\n  nu = max(1, 10+rnorm(1,0,2))\n  omega= c(3,3,3)*exp(rnorm(3,0,0.2))\n  sigmaadd = 0.2*exp(rnorm(1,0,0.2))\n  \n  stan_rdump(c(\"logkwHat\",\"logkaHat\",\"logS2AHat\",\"beta_logka\",\"beta_logkw\",\"eta\",\n               \"rho\",\"nu\",\"omega\",\"sigmaadd\"),\n             file=paste(\"2_initial_model/model_\", i, \".init.R\", sep=\"\"))\n}"
  },
  {
    "objectID": "initial_model.html#summary-of-model-parameters",
    "href": "initial_model.html#summary-of-model-parameters",
    "title": "",
    "section": "Summary of model parameters",
    "text": "Summary of model parameters\nCode for print summary of parameters from supercomputer:\n\n\nCode\nfit &lt;- cmdstanr::as_cmdstan_fit(c('2_initial_model/output_1.csv',\n                                  '2_initial_model/output_2.csv',\n                                  '2_initial_model/output_3.csv',\n                                  '2_initial_model/output_4.csv',\n                                  '2_initial_model/output_5.csv',\n                                  '2_initial_model/output_6.csv',\n                                  '2_initial_model/output_7.csv',\n                                  '2_initial_model/output_8.csv',\n                                  '2_initial_model/output_9.csv',\n                                  '2_initial_model/output_10.csv'))\n\nfit$print(c(\"logkwHat\",\"logkaHat\",\"logS2AHat\",\"beta_logka\",\"beta_logkw\",\"rho\",\"nu\",\"omega\",\"sigmaadd\"), max_rows = 26)\n\n\nCode for print summary of parameters from computer:\n\n\nCode\nload(\"2_initial_model/Fit.Rsave\")\nload(\"2_initial_model/Fit_sample.Rsave\")\n\nprint(fit,pars=c(\"logkwHat\",\"logkaHat\",\"logS2AHat\",\"beta_logka\",\"beta_logkw\",\"rho\",\"nu\",\"omega\",\"sigmaadd\"))\n\n\nInference for Stan model: HPLCizomodel44.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n            mean se_mean   sd  2.5%   25%   50%   75% 97.5% n_eff Rhat\nlogkwHat    1.70    0.01 0.10  1.52  1.63  1.70  1.77  1.89    98 1.05\nlogkaHat   -1.99    0.01 0.06 -2.11 -2.04 -1.99 -1.95 -1.87    91 1.09\nlogS2AHat   1.06    0.00 0.02  1.02  1.04  1.06  1.07  1.09   545 1.01\nbeta_logka  0.25    0.00 0.02  0.21  0.24  0.25  0.26  0.29   124 1.03\nbeta_logkw  0.97    0.00 0.03  0.90  0.94  0.97  0.99  1.03   201 1.02\nrho[1,1]    1.00     NaN 0.00  1.00  1.00  1.00  1.00  1.00   NaN  NaN\nrho[1,2]    0.29    0.00 0.04  0.21  0.26  0.29  0.32  0.36  1572 1.00\nrho[1,3]    0.54    0.00 0.03  0.49  0.52  0.54  0.56  0.59  4342 1.00\nrho[2,1]    0.29    0.00 0.04  0.21  0.26  0.29  0.32  0.36  1572 1.00\nrho[2,2]    1.00    0.00 0.00  1.00  1.00  1.00  1.00  1.00  3956 1.00\nrho[2,3]    0.35    0.00 0.04  0.27  0.32  0.35  0.38  0.42  1662 1.00\nrho[3,1]    0.54    0.00 0.03  0.49  0.52  0.54  0.56  0.59  4342 1.00\nrho[3,2]    0.35    0.00 0.04  0.27  0.32  0.35  0.38  0.42  1662 1.00\nrho[3,3]    1.00    0.00 0.00  1.00  1.00  1.00  1.00  1.00   780 1.00\nnu          5.01    0.03 0.56  4.05  4.62  4.96  5.35  6.25   474 1.01\nomega[1]    0.93    0.00 0.03  0.88  0.91  0.93  0.95  0.99   891 1.01\nomega[2]    0.43    0.00 0.02  0.40  0.42  0.43  0.45  0.47  1436 1.00\nomega[3]    1.43    0.00 0.05  1.33  1.39  1.43  1.46  1.53  1262 1.00\nsigmaadd    0.04    0.00 0.00  0.04  0.04  0.04  0.04  0.04  1429 1.00\n\nSamples were drawn using NUTS(diag_e) at Sun Mar 22 03:24:00 2020.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1)."
  },
  {
    "objectID": "initial_model.html#goodness-of-fit",
    "href": "initial_model.html#goodness-of-fit",
    "title": "",
    "section": "Goodness of fit",
    "text": "Goodness of fit\nThe graphs below were used to check how well the model fits the set of observations. The one on the left compares individual predictions with actual observations. The one on the right shows population predictions with actual observations.\n\n\nCode\npar(mfrow=c(1,2))\nplot(apply(fit_sample$logkCond,2,mean),DS$logk,cex.lab=1.2,xlim=c(-4,6),ylim=c(-3,3),pch=20,col=\"blue\",ylab=expression(\"Log k\"[Obs]),xlab=expression(\"Log k\"[Pred]))\nlines(seq(-4,6,by=0.1),seq(-4,6,by=0.1),lwd=2)\nplot(apply(fit_sample$logkPred,2,mean),DS$logk,cex.lab=1.2,xlim=c(-4,6),ylim=c(-3,3),pch=20,col=\"blue\",ylab=expression(\"Log k\"[Obs]),xlab=expression(\"Log k\"[Pred]))\nlines(seq(-4,6,by=0.1),seq(-4,6,by=0.1),lwd=2)\n\n\n\n\n\n\nAnalysis of eta’s\nIntra-analyte residues for analyte-specific parameters were also determined and are shown below.\n\n\nCode\neta_logka &lt;- apply(drop(fit_sample$eta[,,1]), MARGIN = 2, FUN = mean)\neta_logS2A &lt;- apply(drop(fit_sample$eta[,,2]), MARGIN = 2, FUN = mean)\neta_logkw &lt;- apply(drop(fit_sample$eta[,,3]), MARGIN = 2, FUN = mean)\n\nDS_corr &lt;- as.data.frame(cbind(eta_logka,eta_logS2A,eta_logkw))\n\nlibrary(GGally)\n\nggpairs(DS_corr, \n        columns =  c(\"eta_logkw\",\"eta_logka\",\"eta_logS2A\"),\n        lower=list(continuous='points'), \n        columnLabels = c(\"eta[ logk[w]]\",\"eta[ logk[a]]\",\"eta[ logS[2]]\"),\n        labeller = label_parsed,\n        diag=list(continuous=wrap(\"barDiag\", fill=\"darkblue\"))\n)+ theme_grey(base_size = 15)\n\n\n\n\n\nThe plot shows that the distribution of residuals in the case of the \\(\\log k_a\\) parameter is bimodal. It indicates that analytes with a similar log P are grouped into two clusters.\n\n\nWAIC\nWAIC was also used to evaluate the model. This parameter estimates the effective number of parameters to adjust for overfitting.\n\n\nCode\nlibrary(loo)\nwaic(extract_log_lik(fit)) # waic(fit_sample$log_lik)\n\n\nWarning: \n1417 (27.8%) p_waic estimates greater than 0.4. We recommend trying loo instead.\n\n\n\nComputed from 4000 by 5097 log-likelihood matrix\n\n          Estimate    SE\nelpd_waic   7819.9  97.3\np_waic      1961.6  56.0\nwaic      -15639.9 194.6\n\n1417 (27.8%) p_waic estimates greater than 0.4. We recommend trying loo instead. \n\n\nCode\nloo(extract_log_lik(fit))\n\n\nWarning: Relative effective sample sizes ('r_eff' argument) not specified.\nFor models fit with MCMC, the reported PSIS effective sample sizes and \nMCSE estimates will be over-optimistic.\n\n\nWarning: Some Pareto k diagnostic values are too high. See help('pareto-k-diagnostic') for details.\n\n\n\nComputed from 4000 by 5097 log-likelihood matrix\n\n         Estimate    SE\nelpd_loo   7250.4 103.5\np_loo      2531.2  64.1\nlooic    -14500.8 206.9\n------\nMonte Carlo SE of elpd_loo is NA.\n\nPareto k diagnostic values:\n                         Count Pct.    Min. n_eff\n(-Inf, 0.5]   (good)     2491  48.9%   208       \n (0.5, 0.7]   (ok)       1116  21.9%   57        \n   (0.7, 1]   (bad)      1236  24.2%   13        \n   (1, Inf)   (very bad)  254   5.0%   2         \nSee help('pareto-k-diagnostic') for details."
  },
  {
    "objectID": "initial_model.html#waic",
    "href": "initial_model.html#waic",
    "title": "",
    "section": "WAIC",
    "text": "WAIC\n\n\nCode\nlibrary(loo)\nwaic(extract_log_lik(fit)) # to samo co: waic(fit_sample$log_lik)\n\n\nWarning: \n1417 (27.8%) p_waic estimates greater than 0.4. We recommend trying loo instead.\n\n\n\nComputed from 4000 by 5097 log-likelihood matrix\n\n          Estimate    SE\nelpd_waic   7819.9  97.3\np_waic      1961.6  56.0\nwaic      -15639.9 194.6\n\n1417 (27.8%) p_waic estimates greater than 0.4. We recommend trying loo instead. \n\n\nCode\nloo(extract_log_lik(fit))\n\n\nWarning: Relative effective sample sizes ('r_eff' argument) not specified.\nFor models fit with MCMC, the reported PSIS effective sample sizes and \nMCSE estimates will be over-optimistic.\n\n\nWarning: Some Pareto k diagnostic values are too high. See help('pareto-k-diagnostic') for details.\n\n\n\nComputed from 4000 by 5097 log-likelihood matrix\n\n         Estimate    SE\nelpd_loo   7250.4 103.5\np_loo      2531.2  64.1\nlooic    -14500.8 206.9\n------\nMonte Carlo SE of elpd_loo is NA.\n\nPareto k diagnostic values:\n                         Count Pct.    Min. n_eff\n(-Inf, 0.5]   (good)     2491  48.9%   208       \n (0.5, 0.7]   (ok)       1116  21.9%   57        \n   (0.7, 1]   (bad)      1236  24.2%   13        \n   (1, Inf)   (very bad)  254   5.0%   2         \nSee help('pareto-k-diagnostic') for details."
  },
  {
    "objectID": "initial_model.html#predictions",
    "href": "initial_model.html#predictions",
    "title": "",
    "section": "Predictions",
    "text": "Predictions\nIndividual predictions\n\n\nCode\nlibrary(ggpubr)\nnazwy &lt;- c(\"Caffeine\",\"Chlorpropamide\",\"Doxepin hydrochloride\",\"Perphenazine\",\n  \"Pindolol\",\"Phenylbutazone\",\"Procainamide hydrochloride\",\"Retinoic acid\",\n  \"Sulfaphenazole\",\"Tolbutamide\",\"Ketoprofen\",\"Indomethacin\")\nl_nazwy &lt;- which(DS_names$Analyte[!duplicated(DS_names$ID)] %in% nazwy)\n\nplots &lt;- list()\nfor(i in 1:nAnalytes){\n  l &lt;- apply(drop(fit_sample$logkPlotACond[,i,]), MARGIN = 2, FUN = quantile, probs = c(.025,.5,.975))\n  logk_prct &lt;- as.data.frame(cbind(rep(i,11),fiplot,t(l)))\n  colnames(logk_prct)&lt;-c(\"ID\",\"concentration\",\"low\",\"median\",\"high\")\n  plots[[i]] &lt;- ggplot()+ xlim(0,1) +\n    geom_point(data=subset(DS, ID == i), aes(x = concentration, y = logk), col=\"blue\") +\n    geom_line(data=subset(logk_prct, ID == i), aes(x = fiplot, y = median), col=\"blue\") +\n    geom_ribbon(data=subset(logk_prct, ID == i), aes(x = fiplot, \n                                                     ymin = low, \n                                                     ymax = high), alpha = 0.25, fill=\"blue\")+\n    coord_cartesian(ylim = c(-3, 4)) + \n    labs(title = paste(DS$Names[which(DS$ID==i)]),\n         x = NULL,\n         y = NULL) +\n    theme(text = element_text(size = 9), axis.text = element_text(size = 9),\n          legend.position = \"none\", strip.text = element_text(size = 6)) \n}\nfigure1 &lt;- ggarrange(plotlist = plots[l_nazwy], nrow=3,ncol = 4)\nannotate_figure(figure1,\n                bottom = text_grob(expression(varphi)),\n                left = text_grob(\"log k\", rot = 90))\n\n\n\n\n\nPopulation predictions\n\n\nCode\nplots &lt;- list()\nfor(i in 1:nAnalytes){\n  l &lt;- apply(drop(fit_sample$logkPlotAPred[,i,]), MARGIN = 2, FUN = quantile, probs = c(.025,.5,.975))\n  logk_prct &lt;- as.data.frame(cbind(rep(i,11),fiplot,t(l)))\n  colnames(logk_prct)&lt;-c(\"ID\",\"concentration\",\"low\",\"median\",\"high\")\n  plots[[i]] &lt;- ggplot()+ xlim(0,1) +\n    geom_point(data=subset(DS, ID == i), aes(x = concentration, y = logk), col=\"blue\") +\n    geom_line(data=subset(logk_prct, ID == i), aes(x = fiplot, y = median), col=\"red\") +\n    geom_ribbon(data=subset(logk_prct, ID == i), aes(x = fiplot, \n                                                     ymin = low, \n                                                     ymax = high), alpha = 0.25, fill=\"red\")+\n    coord_cartesian(ylim = c(-3, 4)) + \n    labs(title = paste(DS$Names[which(DS$ID==i)]),\n         x = NULL,\n         y = NULL) +\n    theme(text = element_text(size = 9), axis.text = element_text(size = 9),\n          legend.position = \"none\", strip.text = element_text(size = 6)) \n}\nfigure1 &lt;- ggarrange(plotlist = plots[l_nazwy], nrow=3,ncol = 4)\nannotate_figure(figure1,\n                bottom = text_grob(expression(varphi)),\n                left = text_grob(\"log k\", rot = 90))"
  },
  {
    "objectID": "model_1.html",
    "href": "model_1.html",
    "title": "",
    "section": "",
    "text": "CodeShow All CodeHide All CodeView Source"
  },
  {
    "objectID": "model_1.html#priors",
    "href": "model_1.html#priors",
    "title": "",
    "section": "Priors",
    "text": "Priors\nDue to the appearance of new parameters, prior distributions were reviewed. The clustering of analytes seems to be caused by the presence of analytes in a neutral or dissociated form at the pH of the mobile phase used in this set of experiments.\n\n\nCode\n# load packages\nlibrary(pracma)\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(ggplot2)\nrequire(gridExtra)\n\n\nLoading required package: gridExtra\n\n\n\nAttaching package: 'gridExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n\n\nCode\nlibrary(GGally)\n\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\n\nCode\nlibrary(cmdstanr)\n\n\nThis is cmdstanr version 0.5.2\n\n\n- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n\n\n- CmdStan path: C:/Users/agnie/OneDrive/Dokumenty/.cmdstanr/cmdstan-2.29.2\n\n\n- CmdStan version: 2.29.2\n\n\n\nA newer version of CmdStan is available. See ?install_cmdstan() to install it.\nTo disable this check set option or environment variable CMDSTANR_NO_VER_CHECK=TRUE.\n\n\nCode\nlibrary(rstan)\n\n\nLoading required package: StanHeaders\n\n\nrstan (Version 2.21.5, GitRev: 2e1f913d3ca3)\n\n\nFor execution on a local, multicore CPU with excess RAM we recommend calling\noptions(mc.cores = parallel::detectCores()).\nTo avoid recompilation of unchanged Stan programs, we recommend calling\nrstan_options(auto_write = TRUE)\n\n\nDo not specify '-march=native' in 'LOCAL_CPPFLAGS' or a Makevars file\n\n\nCode\nlibrary(knitr)\nlibrary(reshape2)\nlibrary(bayesplot)\n\n\nThis is bayesplot version 1.9.0\n\n\n- Online documentation and vignettes at mc-stan.org/bayesplot\n\n\n- bayesplot theme set to bayesplot::theme_default()\n\n\n   * Does _not_ affect other ggplot2 plots\n\n\n   * See ?bayesplot_theme_set for details on theme setting\n\n\nCode\nlibrary(posterior)\n\n\nThis is posterior version 1.2.1\n\n\n\nAttaching package: 'posterior'\n\n\nThe following object is masked from 'package:bayesplot':\n\n    rhat\n\n\nThe following objects are masked from 'package:rstan':\n\n    ess_bulk, ess_tail\n\n\nThe following objects are masked from 'package:stats':\n\n    mad, sd, var\n\n\nCode\n# load data\nDS       &lt;- read.csv(here::here(\"1_data/database_stan_1026.csv\"),header = TRUE, sep = \";\", dec = \".\")\nDS_names &lt;- read.csv(here::here(\"1_data/database_stan_1026_analyte_names.csv\"),header = TRUE, sep = \",\", dec = \".\")\nDS_pKa   &lt;- read.csv(here::here(\"1_data/ACD_pKas.csv\"),header = TRUE, sep = \",\", dec = \".\")\n\nnAnalytes=length(unique(DS$ID))\n\n## Calculating charge of analytes in pH=2.658\npH &lt;- 2.658\npKas &lt;- DS_pKa[,3:5]\nfr &lt;- matrix(rep(0,nAnalytes*4),nAnalytes,4)\ncharge &lt;- DS_pKa[,9:12] + DS_pKa[,13:16]\ncharge_pH &lt;- rep(0,nAnalytes)\nfor(i in 1:nAnalytes){\n  pHmpKa &lt;- cbind(0,log(10)^(pH*rep(1,3)-cumsum(pKas[i,])))\n  fr[i, ] &lt;- as.matrix(exp(pHmpKa)/sum(exp(pHmpKa)))\n  charge_pH[i] &lt;- charge[i,which.max(fr[i,])]\n}\n#charge_PH_d &lt;- data.frame(charge_pH)\nrm(pKas,pHmpKa)\n\nDS$compound &lt;- with(DS, ifelse(DS$ID %in% which(charge_pH&lt;0), \"-1\",\n                                 ifelse(DS$ID %in% which(charge_pH==0), \"0\", \"1\")))\n\nggplot(DS) + geom_line(aes(concentration, logk, group=ID,color = compound), alpha = 0.5) + \n  theme_gray() + theme(legend.title = element_text(size=12, color = \"black\", face=\"bold\"),\n                          legend.text = element_text(colour=\"black\", size = 11),\n                          axis.text = element_text(colour=\"black\", size = 11),\n                          axis.title = element_text(colour=\"black\", size = 14)) + \n  guides(colour = guide_legend(override.aes = list(size=2))) +\n  scale_color_manual(labels = c(\"acid\", \"neutral\", \"base\"),values=c(\"red\", \"yellow\", \"blue\"))+\n  labs(y=expression(\"log k\"[\"Obs\"]), x = expression(varphi),colour = \"Compound\")\n\n\n\n\n\nTo obtain an approximate range of model parameters, the data of each analyte separately were fitted, and then combined the individual parameter estimates (the two-stage approach). Analyte-specific chromatographic parameters were estimated for each analyte using the Neue model and least square procedure assuming \\(S_2 = 2\\) for all analytes. This assumption was necessary to obtain stable estimates for all analytes. Then, a linear regression procedure was used to determine the parameters of a regression line between \\(\\log k_{w,i}\\) and \\(\\log P_i\\) as well as between \\(\\log k_{a,i}\\) and \\(\\log P_i\\) separately for neutral and ionized forms of analyte.\n\n\nCode\ninitial_param &lt;- matrix(NA,nAnalytes,3)\nfor(i in 1:nAnalytes){\n  if(length(DS$concentration[which(DS$ID==i)])==1){\n    initial_param[i,2] &lt;- polyfit(-16*DS$concentration[which(DS$ID==i)]/(1+2*DS$concentration[which(DS$ID==i)]),\n                                   DS$logk[which(DS$ID==i)],0)\n    initial_param[i,1] &lt;- -16\n  }else{\n    initial_param[i,1:2] = \n      polyfit(DS$concentration[which(DS$ID==i)]/(1+2*DS$concentration[which(DS$ID==i)]),\n              DS$logk[which(DS$ID==i)],1)\n  }\n}\n\ninitial_param[,3] &lt;- rep(2,nAnalytes)\n\nID        &lt;- unique(DS$ID)\nlogP_ACD  &lt;- DS$logP_ACD[!duplicated(DS$ID)]\nlogkw     &lt;- initial_param[,2]\nlogka     &lt;- initial_param[,2] + initial_param[,1]/3\nlogS2     &lt;- log10(initial_param[,3])\n\nParameters_basic_fit  &lt;-  data.frame(ID,logP_ACD,logkw,logka,logS2)\nrm(ID,logkw,logka,logS2,initial_param)\n\np_neutral_logkw = polyfit(Parameters_basic_fit$logP_ACD[which(charge_pH==0&!is.nan(Parameters_basic_fit$logP_ACD))], \n                          Parameters_basic_fit$logkw[which(charge_pH==0&!is.nan(Parameters_basic_fit$logP_ACD))],1)\np_charged_logkw = polyfit(Parameters_basic_fit$logP_ACD[which(charge_pH==1&!is.nan(Parameters_basic_fit$logP_ACD))], \n                          Parameters_basic_fit$logkw[which(charge_pH==1&!is.nan(Parameters_basic_fit$logP_ACD))],1)\n\nggplot() + geom_point(aes(logP_ACD, Parameters_basic_fit$logkw, color = as.factor(charge_pH)), alpha = 0.5)+\n  scale_color_manual(values=c(\"red\",\"tomato\",\"yellow\",\"skyblue\",\"blue\")) +\n  geom_line(aes(seq(-3,8,by=0.1),polyval(p_neutral_logkw,seq(-3,8,by=0.1))),size=1,colour=\"brown\") +\n  geom_line(aes(seq(-3,8,by=0.1),polyval(p_charged_logkw,seq(-3,8,by=0.1))),size=1,colour=\"navy\") +\n  labs(x = \"log P\", y = expression(\"log k\"[\" w \"]), color = \"Charge\") + \n  theme(legend.title = element_text(size=14, color = \"black\", face=\"bold\"),\n                        legend.text = element_text(colour=\"black\", size = 11),\n                        axis.title=element_text(size=13),\n                        axis.text = element_text(colour=\"black\", size = 11)) +\n  theme_gray()\n\n\nWarning: Removed 1 rows containing missing values (geom_point).\n\n\n\n\n\nCode\np_neutral_logka = polyfit(Parameters_basic_fit$logP_ACD[which(charge_pH==0&!is.nan(Parameters_basic_fit$logP_ACD))], \n                          Parameters_basic_fit$logka[which(charge_pH==0&!is.nan(Parameters_basic_fit$logP_ACD))],1)\np_charged_logka = polyfit(Parameters_basic_fit$logP_ACD[which(charge_pH==1&!is.nan(Parameters_basic_fit$logP_ACD))], \n                          Parameters_basic_fit$logka[which(charge_pH==1&!is.nan(Parameters_basic_fit$logP_ACD))],1)\n\nggplot() + geom_point(aes(logP_ACD, Parameters_basic_fit$logka, color = as.factor(charge_pH)), alpha = 0.5)+\n  scale_color_manual(values=c(\"red\",\"tomato\",\"yellow\",\"skyblue\",\"blue\")) +\n  geom_line(aes(seq(-3,8,by=0.1),polyval(p_neutral_logka,seq(-3,8,by=0.1))),size=1,colour=\"brown\") +\n  geom_line(aes(seq(-3,8,by=0.1),polyval(p_charged_logka,seq(-3,8,by=0.1))),size=1,colour=\"navy\") +\n  labs(x = \"logP\", y = expression(\"logk\"[\" a \"]), color = \"Charge\") + \n  theme(legend.title = element_text(size=14, color = \"black\", face=\"bold\"),\n        legend.text = element_text(colour=\"black\", size = 11),\n        axis.title=element_text(size=13),\n        axis.text = element_text(colour=\"black\", size = 11)) \n\n\nWarning: Removed 1 rows containing missing values (geom_point).\n\n\n\n\n\nBeta(1,1),\\ {k{w_1}} N(1.054, 1.136), {k{w_2}} N(2.053, 1.487),\\ {k{a_1}} N(-3.437, 1.062), {k{a_2}} N(-1.885, 1.006),\\ {S{2_1}}, N(,0.2), {S{2_2}}, N(,0.2), \\ {k{w_1}} N(0.7,0.25), {k{w_2}} N(0.7,0.25),\\ {k{a_1}} N(0.3,0.25), {k{a_2}} N(0.3,0.25), \\ {S{2_1}} N(0,0.25), {S{2_2}} N(0,0.25), \\ N(2.56,1.92), \\ {k{w_1}}{+}(0,1.136), , {k_{a_1}}{+}(0,1.487), , {S_{2_1}}{+}(0,0.2), \\ {k_{w_2}}{+}(0,1.062), , {k_{a_2}}{+}(0,1.006), , {S_{2_2}} _{+}(0,0.2), \\\n\\[\\begin{bmatrix}\n1 & \\rho_{1,2_1} & \\rho_{1,3_1} \\\\\n\\rho_{2,1_1} & 1 & \\rho_{2,3_1} \\\\\n\\rho_{3,1_1} & \\rho_{3,2_1} & 1\n\\end{bmatrix}\\]\n,\n\\[\\begin{bmatrix}\n1 & \\rho_{1,2_2} & \\rho_{1,3_2} \\\\\n\\rho_{2,1_2} & 1 & \\rho_{2,3_2} \\\\\n\\rho_{3,1_2} & \\rho_{3,2_2} & 1\n\\end{bmatrix}\\]\nLKJ(1), \\ _{+}(0,0.067). \\end{align*}"
  },
  {
    "objectID": "model_1.html#analysis",
    "href": "model_1.html#analysis",
    "title": "",
    "section": "Analysis",
    "text": "Analysis\nModel was constructed and implemented in the Stan program.\n\n\nCode\nfunctions{\n  real hplcmodel(real fi, real logkw, real logka, real logS2A){\n    \n    real logk;                  // retention factor\n    real S1;                        // slope coefficient\n    \n    S1 = (logkw - logka)*(1+10^logS2A);\n    logk = logkw - S1 * fi / (1 + 10^logS2A * fi);\n    \n    return logk;\n  }\n}\n\ndata{\n  \n  int nAnalytes;              // number of analytes\n  int nObs;                     // number of observations\n  int analyte[nObs];      // analytes indexes\n  vector[nObs] logkObs; // observed retention factors\n  vector[nObs] fi;          // organic modifier content in the mobile phase\n  real logP[nAnalytes];           // molecular descriptor     \n  int idxmissing[nAnalytes];      // indexes of logP missing value \n  int&lt;lower = 0, upper = 1&gt; run_estimation; // 0 for prior predictive, 1 for estimation\n}\n\nparameters{\n  \n  real&lt;lower=0, upper=1&gt; lambda;  // fraction of analytes belonging to the first cluster\n  vector[2]  logkwHat;                      // mean value of logkw in population\n  ordered[2] logkaHat;            // mean value of logka in population\n  vector[2] logS2AHat;                      // mean curvature coefficient for acetonitrile in population\n  \n  real&lt;lower = 0&gt; sigma;                  // standard deviation for residuals\n  vector&lt;lower = 0&gt;[3] omega1;      // diagonal elements of variance-covariance matrix \n  corr_matrix[3] rho1;                      // correlation matrix\n  vector&lt;lower = 0&gt;[3] omega2;      // diagonal elements of variance-covariance matrix \n  corr_matrix[3] rho2;                      // correlation matrix\n  real beta[6];                                   // coefficient value for molecular descriptor\n  real logPmissing[nAnalytes];    // logP missing values\n  vector[3] param[nAnalytes];\n\n}\n\ntransformed parameters{\n \n  vector[3] miu1[nAnalytes];     \n  vector[3] miu2[nAnalytes];     \n  real logkw[nAnalytes];     // analyte- specific logkw\n  real logka[nAnalytes];     // analyte- specific logka\n  real logS2A[nAnalytes];    // analyte- specific curvature coefficient\n  cov_matrix[3] Omega1;          // variance-covariance matrix\n  cov_matrix[3] Omega2;          // variance-covariance matrix\n  vector[nObs] logkHat;          // mean value of logk in population\n  vector[2] lps[nAnalytes];\n  real log_Z[nAnalytes];\n  real logPr1[nAnalytes];\n\n  Omega1 = quad_form_diag(rho1, omega1);    // diag_matrix(omega) * rho * diag_matrix(omega)\n  Omega2 = quad_form_diag(rho2, omega2);    // diag_matrix(omega) * rho * diag_matrix(omega)\n\n  for(j in 1:nAnalytes){\n    miu1[j,1]  = logkwHat[1]  +  beta[1] * ((1-idxmissing[j])*logP[j]+idxmissing[j]*logPmissing[j]);\n    miu2[j,1]  = logkwHat[2]  +  beta[2] * ((1-idxmissing[j])*logP[j]+idxmissing[j]*logPmissing[j]);\n    miu1[j,2]  = logkaHat[1]  +  beta[3] * ((1-idxmissing[j])*logP[j]+idxmissing[j]*logPmissing[j]); \n    miu2[j,2]  = logkaHat[2]  +  beta[4] * ((1-idxmissing[j])*logP[j]+idxmissing[j]*logPmissing[j]); \n    miu1[j,3]  = logS2AHat[1] +  beta[5] * ((1-idxmissing[j])*logP[j]+idxmissing[j]*logPmissing[j]);\n    miu2[j,3]  = logS2AHat[2] +  beta[6] * ((1-idxmissing[j])*logP[j]+idxmissing[j]*logPmissing[j]);\n  }\n\n    for(j in 1:nAnalytes){\n        logkw[j]  = param[j, 1] ;\n        logka[j]  = param[j, 2] ;\n        logS2A[j] = param[j, 3] ;\n    }\n  \n  for(i in  1:nAnalytes){\n  lps[i,1] = log(lambda)   +  multi_student_t_lpdf(param[i]|7, miu1[i],Omega1);\n  lps[i,2] = log1m(lambda) +  multi_student_t_lpdf(param[i]|7, miu2[i],Omega2);\n  log_Z[i] = log_sum_exp(lps[i,1:2]);\n  logPr1[i] = lps[i,1] - log_Z[i];\n  }\n\n  for(i in 1:nObs){\n    logkHat[i] = hplcmodel(fi[i], logkw[analyte[i]], logka[analyte[i]], logS2A[analyte[i]]);\n }\n  \n}\nmodel{\n  \n  logkwHat[1]  ~ normal(1.054, 1.136);\n  logkwHat[2]  ~ normal(2.053, 1.487);\n  logkaHat[1]  ~ normal(-3.437, 1.062);\n  logkaHat[2]  ~ normal(-1.885, 1.006);\n  logS2AHat[1] ~ normal(log10(2), 0.2);\n  logS2AHat[2] ~ normal(log10(2), 0.2);\n\n  beta[1] ~ normal(0.7,0.25);\n  beta[2] ~ normal(0.7,0.25);\n  beta[3] ~ normal(0.3,0.25);\n  beta[4] ~ normal(0.3,0.25);\n  beta[5] ~ normal(0,0.25);\n  beta[6] ~ normal(0,0.25);\n\n  logPmissing ~ normal(2.56,1.92); // based on logP fit\n\n  omega1[1] ~ normal(0,1.136);\n  omega1[2] ~ normal(0,1.487);\n  omega1[3] ~ normal(0,0.2);\n  rho1   ~ lkj_corr(1);\n  omega2[1] ~ normal(0,1.062);\n  omega2[2] ~ normal(0,1.006);\n  omega2[3] ~ normal(0,0.2);\n  rho2   ~ lkj_corr(1);\n  sigma  ~ normal(0,0.067);\n  lambda ~ beta(1,1);\n\n  for(i in  1:nAnalytes){\n  target += log_Z[i];\n  }\n  \n  if(run_estimation==1){\n  logkObs ~ student_t(7,logkHat, sigma);    // observations\n  }\n}\n\ngenerated quantities{\n    \n  real logkCond[nObs];\n  real log_lik[nObs];\n  real logkHatPred[nObs];\n  real log_likPred[nObs];\n  vector[3] paramPred[nAnalytes];    \n  \n  for(j in 1:nAnalytes){\n    if(bernoulli_rng(lambda) == 1){\n      paramPred[j] =  multi_student_t_rng(7,miu1[j],Omega1);\n    }\n    else{\n      paramPred[j] =  multi_student_t_rng(7,miu2[j],Omega2);\n    }\n  }\n  \n    for(i in 1:nObs){\n    logkCond[i] = student_t_rng(7,logkHat[i], sigma);\n    log_lik[i]  = student_t_lpdf(logkObs[i] | 7,logkHat[i], sigma);\n    logkHatPred[i]  = hplcmodel(fi[i], paramPred[analyte[i],1], paramPred[analyte[i],2], paramPred[analyte[i],3]);\n    log_likPred[i] = student_t_lpdf(logkObs[i] | 7,logkHatPred[i], sigma); \n  }\n \n}\n\n\nThen, the data was added to it and the initial values of the model parameters were determined. In the end, the model was fitted.\n\n\nCode\n# indicating missing value of log P\nidxmissing &lt;- rep(0,1026)\nidxmiss &lt;- which(is.nan(DS$logP_ACD[!duplicated(DS$ID)]))\nidxmissing[idxmiss] &lt;- 1\n\nDS$logP_ACD[which(DS$ID %in% idxmiss)] &lt;- 0\n\nlogP=DS$logP_ACD[!duplicated(DS$ID)]\nnObs=length(DS$ID)\nanalyte=DS$ID\nlogkObs=DS$logk\nfi=DS$concentration\nfiplot=seq(0,1,0.1)\nnfiplot=length(fiplot)\nrun_estimation=1\n\n# data to model\ndatastruct_prior = with(DS,\n                    list(logP=DS$logP_ACD[!duplicated(DS$ID)],\n                       idxmissing=idxmissing,\n                       nAnalytes=nAnalytes,\n                       nObs=nObs,\n                       analyte=DS$ID,\n                       logkObs=DS$logk, \n                       fi=DS$concentration,\n                       nfiplot=length(fi),\n                       fiplot=fi,\n                       run_estimation=0))\n\ndatastruct = with(DS,\n                  list(logP=DS$logP_ACD[!duplicated(DS$ID)],\n                       idxmissing=idxmissing,\n                       nAnalytes=nAnalytes,\n                       nObs=nObs,\n                       analyte=DS$ID,\n                       logkObs=DS$logk, \n                       fi=DS$concentration,\n                       nfiplot=length(fi),\n                       fiplot=fi,\n                       run_estimation=1))\n\n# declaring initial values for each variable in chains\ninit &lt;- function(){\n  list(logkwHat  = rnorm(2,2,0.2),\n       logkaHat  = sort(c(rnorm(1,-4,0.2),rnorm(1,-4,0.2)+max(0,rnorm(1,2,0.5)))),\n       logS2AHat = rnorm(2,log(2),0.2),\n       \n       omega1= c(1,1,1)*exp(rnorm(3,0,0.2)),\n       rho1 = diag(1,3,3),\n       omega2= c(1,1,1)*exp(rnorm(3,0,0.2)),\n       rho2 = diag(1,3,3),\n       \n       beta = c(1,1,0.5,0.5,0,0)*exp(rnorm(6,0,0.2)),\n      \n       lambda=runif(1,0,1),\n\n       param = Parameters_basic_fit[,3:5],\n       sigma  = rlnorm(1,log(0.1),0.2)\n  )\n}\n\n# specifying parameters to analysis \nparametersToPlot &lt;- c(\"logkwHat\",\"logkaHat\",\"logS2AHat\",\"omega1\",\"rho1\",\"omega2\",\"rho2\",\"beta\",\"lambda\",\"sigma\")\notherRVs &lt;- c(\"paramPred\",\"logkw\",\"logka\",\"logS2A\",\"log_lik\",\"logPr1\",\"logkHatPred\",\"log_likPred\")\n\nparameters &lt;- c(parametersToPlot, otherRVs)\nparametersToPlot &lt;- c(\"lp__\", parametersToPlot)\n\n# fitting model\nfit_prior &lt;- stan(file=\"ACN001.stan\",\n            data=datastruct_prior,\n            pars=parameters,\n            iter=2000,\n            warmup=1000,\n            init=init,\n            chains=4,thin=1,control = list(adapt_delta = 0.9,max_treedepth=15))\n\nfit &lt;- stan(file=\"ACN001.stan\",\n                   data=datastruct,\n                   pars=parameters,\n                   iter=2000,\n                   warmup=1000,\n                   init=init,\n                   chains=4,thin=1,control = list(max_treedepth=12))\n\n\nBelow code preapering data to fit the model in supercomputer:\n\n\nCode\nlogP=DS$logP_ACD[!duplicated(DS$ID)]\nnAnalytes=length(unique(DS$ID))\nnObs=length(DS$ID)\nanalyte=DS$ID\nlogkObs=DS$logk\nfi=DS$concentration\nfiplot=seq(0,1,0.1)\nnfiplot=length(fiplot)\nrun_estimation=1\n\nstan_rdump(c(\"logP\",\n             \"nAnalytes\", \n             \"nObs\",\n             \"idxmissing\", \n             \"analyte\", \n             \"logkObs\", \n             \"fi\",\n             \"nfiplot\",\n             \"fiplot\",\n             \"run_estimation\"),\n           file=\"3_model_1/model.data.R\")\n\n\nWarning in stan_rdump(c(\"logP\", \"nAnalytes\", \"nObs\", \"idxmissing\", \"analyte\", :\nobjects not found: idxmissing\n\n\nCode\nfor(i in 1:10){\n  logkwHat  = rnorm(2,2,0.2)\n  logkaHat  = sort(c(rnorm(1,-4,0.2),rnorm(1,-4,0.2)+max(0,rnorm(1,2,0.5))))\n  logS2AHat = rnorm(2,log(2),0.2)\n  omega1= c(1,1,1)*exp(rnorm(3,0,0.2))\n  rho1 = diag(1,3,3)\n  omega2= c(1,1,1)*exp(rnorm(3,0,0.2))\n  rho2 = diag(1,3,3)\n  beta = c(1,1,0.5,0.5,0,0)*exp(rnorm(6,0,0.2))\n  lambda=runif(1,0,1)\n  param = Parameters_basic_fit[,3:5]\n  sigma  = rlnorm(1,log(0.1),0.2)\n  \n  stan_rdump(c(\"logkwHat\",\"logkaHat\",\"logS2AHat\",\"beta\",\"rho1\",\"rho2\",\"lambda\",\"omega1\",\"omega2\",\"sigma\"),\n             file=paste(\"3_model_1/model_\", i, \".init.R\", sep=\"\"))\n}"
  },
  {
    "objectID": "model_1.html#summary-of-model-parameters",
    "href": "model_1.html#summary-of-model-parameters",
    "title": "",
    "section": "Summary of model parameters",
    "text": "Summary of model parameters\nCode for print summary of parameters from supercomputer:\n\n\nCode\nfit &lt;- cmdstanr::as_cmdstan_fit(c('3_model_1/output_1.csv',\n                                  '3_model_1/output_2.csv',\n                                  '3_model_1/output_3.csv',\n                                  '3_model_1/output_4.csv',\n                                  '3_model_1/output_5.csv',\n                                  '3_model_1/output_6.csv',\n                                  '3_model_1/output_7.csv',\n                                  '3_model_1/output_8.csv',\n                                  '3_model_1/output_9.csv',\n                                  '3_model_1/output_10.csv'))\n\nfit$print(c(\"logkwHat\",\"logkaHat\",\"logS2AHat\",\"beta\",\"rho1\",\"rho2\",\"lambda\",\"omega1\",\"omega2\",\"sigma\"), max_rows = 26)\n\n\nCode for print summary of parameters from computer:\n\n\nCode\nload(\"3_model_1/Fit.Rsave\")\nload(\"3_model_1/Fit_sample.Rsave\")\n\nprint(fit,pars=c(\"logkwHat\",\"logkaHat\",\"logS2AHat\",\"beta\",\"rho1\",\"rho2\",\"lambda\",\"omega1\",\"omega2\",\"sigma\"))\n\n\nInference for Stan model: ACN001.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n              mean se_mean   sd  2.5%   25%   50%   75% 97.5% n_eff Rhat\nlogkwHat[1]   1.51       0 0.12  1.28  1.44  1.51  1.59  1.75  2438 1.00\nlogkwHat[2]   2.51       0 0.16  2.19  2.40  2.51  2.61  2.81  2013 1.00\nlogkaHat[1]  -2.75       0 0.10 -2.95 -2.82 -2.75 -2.68 -2.57  1504 1.00\nlogkaHat[2]  -1.10       0 0.02 -1.15 -1.12 -1.10 -1.09 -1.06  5120 1.00\nlogS2AHat[1]  0.46       0 0.03  0.40  0.44  0.46  0.47  0.51  1584 1.00\nlogS2AHat[2]  0.61       0 0.02  0.57  0.60  0.61  0.62  0.65  2181 1.00\nbeta[1]       0.64       0 0.04  0.56  0.61  0.64  0.66  0.71  2719 1.00\nbeta[2]       0.92       0 0.05  0.82  0.89  0.92  0.95  1.03  1333 1.00\nbeta[3]       0.14       0 0.03  0.08  0.12  0.14  0.16  0.20  1721 1.00\nbeta[4]       0.18       0 0.01  0.16  0.17  0.18  0.18  0.19  5305 1.00\nbeta[5]      -0.02       0 0.01 -0.04 -0.03 -0.02 -0.02 -0.01  1634 1.00\nbeta[6]      -0.04       0 0.01 -0.05 -0.05 -0.04 -0.04 -0.03  1463 1.01\nrho1[1,1]     1.00     NaN 0.00  1.00  1.00  1.00  1.00  1.00   NaN  NaN\nrho1[1,2]     0.23       0 0.06  0.12  0.19  0.23  0.28  0.35  2627 1.00\nrho1[1,3]     0.16       0 0.06  0.04  0.12  0.16  0.21  0.28  2345 1.00\nrho1[2,1]     0.23       0 0.06  0.12  0.19  0.23  0.28  0.35  2627 1.00\nrho1[2,2]     1.00       0 0.00  1.00  1.00  1.00  1.00  1.00  4141 1.00\nrho1[2,3]     0.60       0 0.04  0.51  0.57  0.60  0.63  0.68  1909 1.00\nrho1[3,1]     0.16       0 0.06  0.04  0.12  0.16  0.21  0.28  2345 1.00\nrho1[3,2]     0.60       0 0.04  0.51  0.57  0.60  0.63  0.68  1909 1.00\nrho1[3,3]     1.00       0 0.00  1.00  1.00  1.00  1.00  1.00  1457 1.00\nrho2[1,1]     1.00     NaN 0.00  1.00  1.00  1.00  1.00  1.00   NaN  NaN\nrho2[1,2]     0.12       0 0.06 -0.01  0.08  0.12  0.16  0.24  1992 1.00\nrho2[1,3]     0.57       0 0.04  0.48  0.54  0.57  0.60  0.66  1839 1.00\nrho2[2,1]     0.12       0 0.06 -0.01  0.08  0.12  0.16  0.24  1992 1.00\nrho2[2,2]     1.00       0 0.00  1.00  1.00  1.00  1.00  1.00  3948 1.00\nrho2[2,3]    -0.40       0 0.06 -0.51 -0.44 -0.40 -0.37 -0.29  1988 1.00\nrho2[3,1]     0.57       0 0.04  0.48  0.54  0.57  0.60  0.66  1839 1.00\nrho2[3,2]    -0.40       0 0.06 -0.51 -0.44 -0.40 -0.37 -0.29  1988 1.00\nrho2[3,3]     1.00       0 0.00  1.00  1.00  1.00  1.00  1.00  1187 1.00\nlambda        0.46       0 0.02  0.43  0.45  0.46  0.47  0.50  4038 1.00\nomega1[1]     1.13       0 0.06  1.02  1.09  1.13  1.17  1.25  2095 1.00\nomega1[2]     0.80       0 0.05  0.72  0.77  0.80  0.83  0.90  1474 1.00\nomega1[3]     0.23       0 0.01  0.20  0.22  0.23  0.23  0.25  1434 1.00\nomega2[1]     1.41       0 0.07  1.28  1.36  1.41  1.45  1.55  1654 1.00\nomega2[2]     0.20       0 0.01  0.18  0.19  0.20  0.21  0.22  2309 1.00\nomega2[3]     0.18       0 0.01  0.16  0.17  0.18  0.18  0.20  1884 1.00\nsigma         0.03       0 0.00  0.03  0.03  0.03  0.03  0.03  1250 1.00\n\nSamples were drawn using NUTS(diag_e) at Wed Nov 04 04:21:39 2020.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1)."
  },
  {
    "objectID": "model_1.html#goodness-of-fit",
    "href": "model_1.html#goodness-of-fit",
    "title": "",
    "section": "Goodness of fit",
    "text": "Goodness of fit\n\n\nCode\nlibrary(metRology) # function rt.scaled\n\n\n\nAttaching package: 'metRology'\n\n\nThe following objects are masked from 'package:base':\n\n    cbind, rbind\n\n\nCode\nhplc &lt;- function(fi,logkw,logka,logS2A){\n  S1 = (logkw - logka)*(1+10^logS2A)\n  logk = logkw - S1 * fi / (1 + 10^logS2A * fi)\n  return(logk)\n}\n\nlogkHatCond &lt;-array(rep(5097*4000),dim=c(4000,5097))\nlogkCond &lt;-array(rep(5097*4000),dim=c(4000,5097))\nfor(j in 1:nObs){\n    for(k in 1:4000){\n      logkHatCond[k,j]  = hplc(DS$concentration[j], fit_sample$logkw[k,DS$ID[j]],\n                                     fit_sample$logka[k,DS$ID[j]], fit_sample$logS2A[k,DS$ID[j]])\n      logkCond[k,j]     = rt.scaled(1,7,logkHatCond[k,j], fit_sample$sigma[k])\n    }\n}\n\nlogkPred &lt;-array(rep(5097*4000),dim=c(4000,5097))\nfor(j in 1:nObs){\n  for(k in 1:4000){\n    logkPred[k,j]       = rt.scaled(1,7,fit_sample$logkHatPred[k,j], fit_sample$sigma[k])\n  }\n}\n\npar(mfrow=c(1,2))\nplot(apply(logkCond,2,mean),DS$logk,cex.lab=1.2,xlim=c(-4,6),ylim=c(-3,3),pch=20,col=\"blue\",ylab=expression(\"Log k\"[Obs]),xlab=expression(\"Log k\"[Pred]))\nlines(seq(-4,6,by=0.1),seq(-4,6,by=0.1),lwd=2)\nplot(apply(logkPred,2,mean),DS$logk,cex.lab=1.2,xlim=c(-4,6),ylim=c(-3,3),pch=20,col=\"blue\",ylab=expression(\"Log k\"[Obs]),xlab=expression(\"Log k\"[Pred]))\nlines(seq(-4,6,by=0.1),seq(-4,6,by=0.1),lwd=2)\n\n\n\n\n\n\nWAIC\n\n\nCode\nlibrary(loo)\nwaic(extract_log_lik(fit)) # to samo co: waic(fit_sample$log_lik)\n\n\nWarning: \n2244 (44.0%) p_waic estimates greater than 0.4. We recommend trying loo instead.\n\n\n\nComputed from 4000 by 5097 log-likelihood matrix\n\n          Estimate    SE\nelpd_waic   7767.1 183.9\np_waic      3619.4 165.5\nwaic      -15534.1 367.8\n\n2244 (44.0%) p_waic estimates greater than 0.4. We recommend trying loo instead. \n\n\nCode\nloo(extract_log_lik(fit))\n\n\nWarning: Relative effective sample sizes ('r_eff' argument) not specified.\nFor models fit with MCMC, the reported PSIS effective sample sizes and \nMCSE estimates will be over-optimistic.\n\n\nWarning: Some Pareto k diagnostic values are too high. See help('pareto-k-diagnostic') for details.\n\n\n\nComputed from 4000 by 5097 log-likelihood matrix\n\n         Estimate    SE\nelpd_loo   7385.6 120.0\np_loo      4000.8  94.2\nlooic    -14771.2 240.0\n------\nMonte Carlo SE of elpd_loo is NA.\n\nPareto k diagnostic values:\n                         Count Pct.    Min. n_eff\n(-Inf, 0.5]   (good)     2919  57.3%   83        \n (0.5, 0.7]   (ok)        917  18.0%   55        \n   (0.7, 1]   (bad)       912  17.9%   11        \n   (1, Inf)   (very bad)  349   6.8%   1         \nSee help('pareto-k-diagnostic') for details."
  },
  {
    "objectID": "model_1.html#predictions",
    "href": "model_1.html#predictions",
    "title": "",
    "section": "Predictions",
    "text": "Predictions\nIndividual predictions\n\n\nCode\nlibrary(ggpubr)\nnazwy &lt;- c(\"Caffeine\",\"Chlorpropamide\",\"Doxepin hydrochloride\",\"Perphenazine\",\n  \"Pindolol\",\"Phenylbutazone\",\"Procainamide hydrochloride\",\"Retinoic acid\",\n  \"Sulfaphenazole\",\"Tolbutamide\",\"Ketoprofen\",\"Indomethacin\")\nl_nazwy &lt;- which(DS_names$Analyte[!duplicated(DS_names$ID)] %in% nazwy)\n\nlogkHatPlotACond &lt;-array(rep(0,11*1026*4000),dim=c(4000,1026,11))\nlogkPlotACond &lt;-array(rep(0,11*1026*4000),dim=c(4000,1026,11))\n\nfor(j in 1:nAnalytes){\n  for(z in 1:nfiplot){\n    for(k in 1:4000){\n      logkHatPlotACond[k,j,z]   = hplc(fiplot[z], fit_sample$logkw[k,j],\n                                     fit_sample$logka[k,j], fit_sample$logS2A[k,j])\n      logkPlotACond[k,j,z]      = rt.scaled(1,7,logkHatPlotACond[k,j,z], fit_sample$sigma[k])\n    }\n  }\n}\n\nplots &lt;- list()\nfor(i in 1:nAnalytes){\n  l &lt;- apply(drop(logkPlotACond[,i,]), MARGIN = 2, FUN = quantile, probs = c(.025,.5,.975))\n  logk_prct &lt;- as.data.frame(cbind(rep(i,11),fiplot,t(l)))\n  colnames(logk_prct)&lt;-c(\"ID\",\"concentration\",\"low\",\"median\",\"high\")\n  plots[[i]] &lt;- ggplot()+ xlim(0,1) +\n    geom_point(data=subset(DS, ID == i), aes(x = concentration, y = logk), col=\"blue\") +\n    geom_line(data=subset(logk_prct, ID == i), aes(x = fiplot, y = median), col=\"blue\") +\n    geom_ribbon(data=subset(logk_prct, ID == i), aes(x = fiplot, \n                                                     ymin = low, \n                                                     ymax = high), alpha = 0.25, fill=\"blue\")+\n    coord_cartesian(ylim = c(-3, 4)) + \n    labs(title = paste(DS$Names[which(DS$ID==i)]),\n         x = NULL,\n         y = NULL) +\n    theme(text = element_text(size = 9), axis.text = element_text(size = 9),\n          legend.position = \"none\", strip.text = element_text(size = 6)) \n}\nfigure1 &lt;- ggarrange(plotlist = plots[l_nazwy], nrow=3,ncol = 4)\nannotate_figure(figure1,\n                bottom = text_grob(expression(varphi)),\n                left = text_grob(\"log k\", rot = 90))\n\n\n\n\n\nPopulation predictions\n\n\nCode\nlogkHatPlotAPred &lt;-array(rep(0,11*1026*4000),dim=c(4000,1026,11))\nlogkPlotAPred &lt;-array(rep(0,11*1026*4000),dim=c(4000,1026,11))\n\nfor(j in 1:nAnalytes){\n  for(z in 1:nfiplot){\n    for(k in 1:4000){\n      logkHatPlotAPred[k,j,z]   = hplc(fiplot[z], fit_sample$paramPred[k,j,1],\n                                     fit_sample$paramPred[k,j,2], fit_sample$paramPred[k,j,3])\n      logkPlotAPred[k,j,z]      = rt.scaled(1,7,logkHatPlotAPred[k,j,z], fit_sample$sigma[k])\n    }\n  }\n}\n\nplots &lt;- list()\nfor(i in 1:nAnalytes){\n  l &lt;- apply(drop(logkPlotAPred[,i,]), MARGIN = 2, FUN = quantile, probs = c(.025,.5,.975))\n  logk_prct &lt;- as.data.frame(cbind(rep(i,11),fiplot,t(l)))\n  colnames(logk_prct)&lt;-c(\"ID\",\"concentration\",\"low\",\"median\",\"high\")\n  plots[[i]] &lt;- ggplot()+ xlim(0,1) +\n    geom_point(data=subset(DS, ID == i), aes(x = concentration, y = logk), col=\"blue\") +\n    geom_line(data=subset(logk_prct, ID == i), aes(x = fiplot, y = median), col=\"red\") +\n    geom_ribbon(data=subset(logk_prct, ID == i), aes(x = fiplot, \n                                                     ymin = low, \n                                                     ymax = high), alpha = 0.25, fill=\"red\")+\n    coord_cartesian(ylim = c(-3, 4)) + \n    labs(title = paste(DS$Names[which(DS$ID==i)]),\n         x = NULL,\n         y = NULL) +\n    theme(text = element_text(size = 9), axis.text = element_text(size = 9),\n          legend.position = \"none\", strip.text = element_text(size = 6)) \n}\nfigure1 &lt;- ggarrange(plotlist = plots[l_nazwy], nrow=3,ncol = 4)\nannotate_figure(figure1,\n                bottom = text_grob(expression(varphi)),\n                left = text_grob(\"log k\", rot = 90))"
  },
  {
    "objectID": "model_1.html#probability-beloging-to-clusters",
    "href": "model_1.html#probability-beloging-to-clusters",
    "title": "",
    "section": "Probability beloging to clusters",
    "text": "Probability beloging to clusters\nThe chart below shows the values of the probabilities of belonging of individual analytes to the first cluster.\n\n\nCode\nvector &lt;- apply(fit_sample$logPr1,2,mean)\nprobability_I_cluster &lt;- 10^(vector)\ndata &lt;- data.frame(unique(DS$ID),probability_I_cluster)\n\nggplot(data,aes(data[,1],data[,2]))+geom_point()+xlab(\"analyte index\")+ylab(\"probability\")\n\n\n\n\n\nResidual distributions of initial model were determined taking into account belonging to the first (blue) and the second (red) cluster.\n\n\nCode\ndata_cluster &lt;- cbind(DS$ID[!duplicated(DS$ID)],probability_I_cluster)\ncluster &lt;- as.vector(ifelse(probability_I_cluster&gt;0.5,\"I\",\"II\"))\n\nload(\"2_initial_model/Fit_sample.Rsave\")\n\neta_logka &lt;- apply(drop(fit_sample$eta[,,1]), MARGIN = 2, FUN = mean)\neta_logS2A &lt;- apply(drop(fit_sample$eta[,,2]), MARGIN = 2, FUN = mean)\neta_logkw &lt;- apply(drop(fit_sample$eta[,,3]), MARGIN = 2, FUN = mean)\n\nDS_corr &lt;- as.data.frame(cbind(eta_logka,eta_logS2A,eta_logkw,cluster))\ncolnames(DS_corr) &lt;- c(\"eta_logka\",\"eta_logS2A\",\"eta_logkw\",\"cluster\")\nDS_corr[,1] &lt;-as.numeric(as.character(DS_corr[,1]))\nDS_corr[,2] &lt;-as.numeric(as.character(DS_corr[,2]))\nDS_corr[,3] &lt;-as.numeric(as.character(DS_corr[,3]))\n\nlibrary(GGally)\nlibrary(ggplot2)\n\nggpairs(DS_corr, \n        columns = c(\"eta_logkw\",\"eta_logka\",\"eta_logS2A\"),\n        mapping = aes(color = cluster),\n        columnLabels = c(\"eta[ logk[w]]\",\"eta[ logk[a]]\",\"eta[ logS[2]]\"),\n        labeller = label_parsed\n)+ theme_grey(base_size = 20) +theme(axis.text = element_text(size = 10))"
  },
  {
    "objectID": "model_2.html",
    "href": "model_2.html",
    "title": "",
    "section": "",
    "text": "CodeShow All CodeHide All CodeView Source"
  },
  {
    "objectID": "model_2.html#priors",
    "href": "model_2.html#priors",
    "title": "",
    "section": "Priors",
    "text": "Priors\nIn this model, the same priors as in the model 1 were adopted.\n\\[\\begin{align*}\n\\theta_{\\log k_{w_1}} \\sim N(1.054, 1.136),  \\quad \\theta_{\\log k_{w_2}} \\sim N(2.053, 1.487),\\\\\n\\theta_{\\log k_{a_1}} \\sim N(-3.437, 1.062), \\quad \\theta_{\\log k_{a_2}} \\sim N(-1.885, 1.006),\\\\\n\\theta_{\\log S_{2_1}},  \\sim N(\\log 2,0.2), \\quad \\theta_{\\log S_{2_2}},  \\sim N(\\log 2,0.2), \\\\\n\\beta_{\\log k_{w_1}} \\sim N(0.7,0.25), \\quad \\beta_{\\log k_{w_2}} \\sim N(0.7,0.25),\\\\\n\\beta_{\\log k_{a_1}} \\sim N(0.3,0.25), \\quad \\beta_{\\log k_{a_2}} \\sim N(0.3,0.25), \\\\\n\\beta_{\\log S_{2_1}} \\sim N(0,0.25), \\quad \\beta_{\\log S_{2_2}} \\sim N(0,0.25), \\\\\n\\text{logPmissing} \\sim N(2.56,1.92), \\\\\n\\omega_{\\log k_{w_1}}\\sim \\textnormal{N}_{+}(0,1.136),  \\, \\omega_{\\log k_{a_1}}\\sim \\textnormal{N}_{+}(0,1.487), \\, \\omega_{\\log S_{2_1}}\\sim \\textnormal{N}_{+}(0,0.2), \\\\ \\omega_{\\log k_{w_2}}\\sim \\textnormal{N}_{+}(0,1.062), \\, \\omega_{\\log k_{a_2}}\\sim \\textnormal{N}_{+}(0,1.006), \\, \\omega_{\\log S_{2_2}} \\sim \\textnormal{N}_{+}(0,0.2), \\\\\n\\begin{bmatrix}\n1 & \\rho_{1,2_1} & \\rho_{1,3_1} \\\\\n\\rho_{2,1_1} & 1 & \\rho_{2,3_1} \\\\\n\\rho_{3,1_1} & \\rho_{3,2_1} & 1\n\\end{bmatrix}, \\begin{bmatrix}\n1 & \\rho_{1,2_2} & \\rho_{1,3_2} \\\\\n\\rho_{2,1_2} & 1 & \\rho_{2,3_2} \\\\\n\\rho_{3,1_2} & \\rho_{3,2_2} & 1\n\\end{bmatrix} \\sim LKJ(1), \\\\\n\\sigma \\sim \\textnormal{N}_{+}(0,0.067).\n\\end{align*}\\]\nDue to the implementation of the model in the program, the state was assumed and using the built-in inv_logit function ( \\(\\text{inv_logit}(u)=\\frac{1}{1+e^{-u}}\\)), it was assumed that:\n\\[\\begin{align*}\n\\eta \\sim \\textnormal{Student t}(7,0,0.23).\n\\end{align*}\\]"
  },
  {
    "objectID": "model_2.html#analysis",
    "href": "model_2.html#analysis",
    "title": "",
    "section": "Analysis",
    "text": "Analysis\nModel was constructed and implemented in the Stan program.\n\n\nCode\nfunctions{\n  real hplcmodel(real fi, real logkw, real logka, real logS2A){\n    \n    real logk;                  // retention factor\n    real S1;                        // slope coefficient\n    \n    S1 = (logkw - logka)*(1+10^logS2A);\n    logk = logkw - S1 * fi / (1 + 10^logS2A * fi);\n    \n    return logk;\n  }\n}\n\ndata{\n  int nAnalytes;              // number of analytes\n  int nObs;                     // number of observations\n  int analyte[nObs];        // analytes indexes\n  vector[nObs] logkObs; // observed retention factors\n  vector[nObs] fi;          // organic modifier content in the mobile phase\n  real logP[nAnalytes];         // molecular descriptor      \n  int idxmissing[nAnalytes];    // indexes of logP missing value\n  real&lt;lower=0, upper=1&gt; rawlambdai[nAnalytes];  // ratio of ionized to total concentration of a compound\n  \n  int nfiplot;                                // number of fi for plotting\n  vector[nfiplot] fiplot;               // organic modifier content in the mobile phase\n  \n  int&lt;lower = 0, upper = 1&gt; run_estimation; // 0 for prior predictive, 1 for estimation\n}\n\n\ntransformed data {\n  real oddsi[nAnalytes];\n \nfor(j in 1:nAnalytes){\n  oddsi[j] = logit(rawlambdai[j]);\n}\n}\n\nparameters{\n  ordered[2] logkwHat;                  // mean value of logkw in population\n  ordered[2] logkaHat;          // mean value of logka in population\n  vector[2] logS2AHat;                  // mean curvature coefficient for acetonitrile in population\n\n  real&lt;lower = 0&gt; sigma;                    // standard deviation for residuals\n  vector&lt;lower = 0&gt;[3] omega1;      // diagonal elements of variance-covariance matrix \n  corr_matrix[3] rho1;                    // correlation matrix\n  vector&lt;lower = 0&gt;[3] omega2;    // diagonal elements of variance-covariance matrix \n  corr_matrix[3] rho2;                      // correlation matrix\n  real beta[6];                                   // coefficient value for molecular descriptor\n  real logPmissing[nAnalytes];    // logP Missing values\n  vector[3] param1[nAnalytes];\n  vector[3] param2[nAnalytes];\n  real eta[nAnalytes];\n}\n\ntransformed parameters{\n \n  vector[3] miu1[nAnalytes];     \n  vector[3] miu2[nAnalytes];     \n  real logka[nAnalytes];     // mean value of logka in population\n  real logkw[nAnalytes];     // mean value of logkw in population\n  real logS2A[nAnalytes];    // mean curvature coefficient for acetonitrile in population\n  cov_matrix[3] Omega1;          // variance-covariance matrix\n  cov_matrix[3] Omega2;          // variance-covariance matrix\n  vector[nObs] logkHat;          // mean value of logk in population\n  real&lt;lower=0, upper=1&gt; frac[nAnalytes];\n\n  Omega1 = quad_form_diag(rho1, omega1);    // diag_matrix(omega) * rho * diag_matrix(omega)\n  Omega2 = quad_form_diag(rho2, omega2);    // diag_matrix(omega) * rho * diag_matrix(omega)\n\n  for(j in 1:nAnalytes){\n    miu1[j,1]  = logkwHat[1]  +  beta[1] * ((1-idxmissing[j])*logP[j]+idxmissing[j]*logPmissing[j]);\n    miu2[j,1]  = logkwHat[2]  +  beta[2] * ((1-idxmissing[j])*logP[j]+idxmissing[j]*logPmissing[j]);\n    miu1[j,2]  = logkaHat[1]  +  beta[3] * ((1-idxmissing[j])*logP[j]+idxmissing[j]*logPmissing[j]); \n    miu2[j,2]  = logkaHat[2]  +  beta[4] * ((1-idxmissing[j])*logP[j]+idxmissing[j]*logPmissing[j]); \n    miu1[j,3]  = logS2AHat[1] +  beta[5] * ((1-idxmissing[j])*logP[j]+idxmissing[j]*logPmissing[j]);\n    miu2[j,3]  = logS2AHat[2] +  beta[6] * ((1-idxmissing[j])*logP[j]+idxmissing[j]*logPmissing[j]);\n    frac[j]  = inv_logit(oddsi[j] + eta[j]);\n  }\n\n    for(j in 1:nAnalytes){\n    logkw[j]  = param1[j, 1]*frac[j] + param2[j, 1]*(1-frac[j]);\n    logka[j]  = param1[j, 2]*frac[j] + param2[j, 2]*(1-frac[j]);\n    logS2A[j] = param1[j, 3]*frac[j] + param2[j, 3]*(1-frac[j]);\n    }\n  \n\n  for(i in 1:nObs){\n    logkHat[i] = hplcmodel(fi[i], logkw[analyte[i]], logka[analyte[i]], logS2A[analyte[i]]);\n }\n  \n}\nmodel{\n  \n  logkwHat[1]  ~ normal(1.054, 1.136);\n  logkwHat[2]  ~ normal(2.053, 1.487);\n  logkaHat[1]  ~ normal(-3.437, 1.062);\n  logkaHat[2]  ~ normal(-1.885, 1.006);\n  logS2AHat[1] ~ normal(log10(2), 0.2);\n  logS2AHat[2] ~ normal(log10(2), 0.2);\n\n  beta[1] ~ normal(0.7,0.25);\n  beta[2] ~ normal(0.7,0.25);\n  beta[3] ~ normal(0.3,0.25);\n  beta[4] ~ normal(0.3,0.25);\n  beta[5] ~ normal(0,0.25);\n  beta[6] ~ normal(0,0.25);\n\n  logPmissing ~ normal(2.56,1.92); // based on logP fit\n\n  eta ~ student_t(7,0,0.23);\n\n  omega1[1] ~ normal(0,1.136);\n  omega1[2] ~ normal(0,1.487);\n  omega1[3] ~ normal(0,0.2);\n  rho1   ~ lkj_corr(1);\n  omega2[1] ~ normal(0,1.062);\n  omega2[2] ~ normal(0,1.006);\n  omega2[3] ~ normal(0,0.2);\n  rho2   ~ lkj_corr(1);\n  sigma  ~ normal(0,0.067);\n\n  for(i in  1:nAnalytes){\n  param1[i] ~ multi_student_t(7, miu1[i],Omega1);\n  param2[i] ~ multi_student_t(7, miu2[i],Omega2);\n  }\n  \n  if(run_estimation==1){\n  logkObs ~ student_t(7,logkHat, sigma);    // observations\n  }\n}\n\ngenerated quantities{\n\n  real logkCond[nObs];\n  real log_lik[nObs];\n  real log_likPred[nObs];\n  real logkHatPred[nObs];\n  real logkaPred[nAnalytes];\n  real logkwPred[nAnalytes];\n  real logS2APred[nAnalytes];\n  real&lt;lower=0, upper=1&gt; fracPred[nAnalytes];\n  \n  matrix[nAnalytes,nfiplot] logkHatPlotACond;\n  matrix[nAnalytes,nfiplot] logkPlotACond;\n\n  vector[3] paramPred1[nAnalytes];   \n  vector[3] paramPred2[nAnalytes];\n  \n  for(j in 1:nAnalytes){\n\n  real etaPred[nAnalytes];\n\n  etaPred[j] = student_t_rng(7,0, 0.23);\n  fracPred[j]  = inv_logit(oddsi[j] + etaPred[j]);\n  \n  paramPred1[j] =  multi_student_t_rng(7,miu1[j],Omega1);\n  paramPred2[j] =  multi_student_t_rng(7,miu2[j],Omega2);\n\n  logkwPred[j]  = paramPred1[j, 1]*fracPred[j] + paramPred2[j, 1]*(1-fracPred[j]);\n  logkaPred[j]  = paramPred1[j, 2]*fracPred[j] + paramPred2[j, 2]*(1-fracPred[j]);\n  logS2APred[j] = paramPred1[j, 3]*fracPred[j] + paramPred2[j, 3]*(1-fracPred[j]);\n  }\n  \n  for(i in 1:nObs){\n    logkCond[i] = student_t_rng(7,logkHat[i], sigma);\n    log_lik[i]  = student_t_lpdf(logkObs[i] | 7,logkHat[i], sigma);\n    logkHatPred[i]  = hplcmodel(fi[i], logkwPred[analyte[i]], logkaPred[analyte[i]], logS2APred[analyte[i]]);\n    log_likPred[i] = student_t_lpdf(logkObs[i] | 7,logkHatPred[i], sigma); \n\n  }\n}\n\n\nThen, the data was added to it and the initial values of the model parameters were determined. In the end, the model was fitted.\n\n\nCode\n# load packages\nlibrary(pracma)\nlibrary(dplyr)\nlibrary(ggplot2)\nrequire(gridExtra)\nlibrary(GGally)\nlibrary(cmdstanr)\nlibrary(rstan)\nlibrary(knitr)\nlibrary(reshape2)\nlibrary(bayesplot)\nlibrary(posterior)\n\n# load data\nDS       &lt;- read.csv(here::here(\"1_data/database_stan_1026.csv\"),header = TRUE, sep = \";\", dec = \".\")\nDS_names &lt;- read.csv(here::here(\"1_data/database_stan_1026_analyte_names.csv\"),header = TRUE, sep = \",\", dec = \".\")\nDS_pKa   &lt;- read.csv(here::here(\"1_data/ACD_pKas.csv\"),header = TRUE, sep = \",\", dec = \".\")\n\nnAnalytes=length(unique(DS$ID))\n\n# calculating fractions of analytes in pH=2.658\npH &lt;- 2.658\npKas &lt;- DS_pKa[,3:5]\nfr &lt;- matrix(rep(0,nAnalytes*4),nAnalytes,4)\ncharge &lt;- DS_pKa[,9:12] + DS_pKa[,13:16]\ncharge_pH &lt;- rep(0,nAnalytes)\nlambda &lt;- rep(0,1026)\nfor(i in 1:nAnalytes){\n  cums&lt;-cumsum(c(pKas[i,]))\n  x&lt;-c()\n  x[1]&lt;-1\n  for(j in 1:3){\n    x[j+1]&lt;- 10^(j*pH-cums[j])\n  }\n  fr[i, ] &lt;- as.matrix(x/sum(x))\n  charge_pH[i] &lt;- charge[i,which.max(fr[i,])]\n  lambda[i] &lt;- sum(fr[i,which(charge[i,]==0)])\n}\n\n# calculation of logk versus fi curves\ninitial_param &lt;- matrix(NA,nAnalytes,3)\nfor(i in 1:nAnalytes){\n  if(length(DS$concentration[which(DS$ID==i)])==1){\n    initial_param[i,2] &lt;- polyfit(-16*DS$concentration[which(DS$ID==i)]/(1+2*DS$concentration[which(DS$ID==i)]),\n                                  DS$logk[which(DS$ID==i)],0)\n    initial_param[i,1] &lt;- -16\n  }else{\n    initial_param[i,1:2] = \n      polyfit(DS$concentration[which(DS$ID==i)]/(1+2*DS$concentration[which(DS$ID==i)]),\n              DS$logk[which(DS$ID==i)],1)\n  }\n}\ninitial_param[,3] &lt;- rep(2,nAnalytes)\n\nID        &lt;- unique(DS$ID)\nlogP_ACD  &lt;- DS$logP_ACD[!duplicated(DS$ID)]\nlogkw     &lt;- initial_param[,2]\nlogka     &lt;- initial_param[,2] + initial_param[,1]/3\nlogS2     &lt;- log10(initial_param[,3])\n\nParameters_basic_fit  &lt;-  data.frame(ID,logP_ACD,logkw,logka,logS2)\nrm(ID,logkw,logka,logS2,initial_param)\n\n# indicating missing value of log P\nidxmissing &lt;- rep(0,1026)\nidxmiss &lt;- which(is.nan(DS$logP_ACD[!duplicated(DS$ID)]))\nidxmissing[idxmiss] &lt;- 1\n\nDS$logP_ACD[which(DS$ID %in% idxmiss)] &lt;- 0\n\nlambda[which(lambda&gt;0.999)]=0.999\nlambda[which(lambda&lt;0.001)]=0.001\n\n\n\n\nCode\nlogP=DS$logP_ACD[!duplicated(DS$ID)]\nnObs=length(DS$ID)\nanalyte=DS$ID\nlogkObs=DS$logk\nfi=DS$concentration\nfiplot=seq(0,1,0.1)\nnfiplot=length(fiplot)\nrun_estimation=1\n\n# data to model\ndatastruct_prior = with(DS,\n                    list(logP=DS$logP_ACD[!duplicated(DS$ID)],\n                       idxmissing=idxmissing,\n                       nAnalytes=nAnalytes,\n                       nObs=nObs,\n                       analyte=DS$ID,\n                       logkObs=DS$logk, \n                       fi=DS$concentration,\n                       rawlambdai=1-lambda,\n                       nfiplot=length(fi),\n                       fiplot=fi,\n                       run_estimation=0))\n\ndatastruct = with(DS,\n                  list(logP=DS$logP_ACD[!duplicated(DS$ID)],\n                       idxmissing=idxmissing,\n                       nAnalytes=nAnalytes,\n                       nObs=nObs,\n                       analyte=DS$ID,\n                       logkObs=DS$logk, \n                       fi=DS$concentration,\n                       rawlambdai=1-lambda,\n                       nfiplot=length(fi),\n                       fiplot=fi,\n                       run_estimation=1))\n\n# declaring initial values for each variable in chains\ninit &lt;- function(){\n  list(logkwHat  = sort(c(rnorm(1,2,0.2),rnorm(1,2,0.2)+max(0,rnorm(1,2,0.5)))),\n       logkaHat  = sort(c(rnorm(1,-4,0.2),rnorm(1,-4,0.2)+max(0,rnorm(1,2,0.5)))),\n       logS2AHat = rnorm(2,log(2),0.2),\n       \n       omega1= c(1,1,0.1)*exp(rnorm(3,0,0.2)),\n       rho1 = diag(1,3,3),\n       omega2= c(1,1,0.1)*exp(rnorm(3,0,0.2)),\n       rho2 = diag(1,3,3),\n       \n       beta = c(0.7,0.7,0.5,0.5,0,0)*exp(rnorm(6,0,0.2)),\n       \n       param1 = Parameters_basic_fit[,3:5]*0.9,\n       param2 = Parameters_basic_fit[,3:5]*1.1,\n       sigma  = rlnorm(1,log(0.1),0.2)\n  )\n}\n\n# specifying parameters to analysis \nparametersToPlot &lt;- c(\"logkwHat\",\"logkaHat\",\"logS2AHat\",\"omega1\",\"rho1\",\"omega2\",\"rho2\",\"beta\",\n                      \"param1\",\"param2\",\"sigma\",\"logPmissing\")\notherRVs &lt;- c(\"logkCond\",\"logkPlotACond\",\"fracPred\",\"log_lik\",\"logkwPred\",\"logkaPred\",\"logS2APred\",\n              \"logkHat\",\"paramPred1\",\"paramPred2\",\"logkw\",\"logka\",\"logS2A\",\"logkHatPred\",\"log_likPred\")\n\nparameters &lt;- c(parametersToPlot, otherRVs)\nparametersToPlot &lt;- c(\"lp__\", parametersToPlot)\n\n# fitting model\nfit_prior &lt;- stan(file=\"ACN002.stan\",\n            data=datastruct_prior,\n            pars=parameters,\n            iter=2000,\n            warmup=1000,\n            init=init,\n            chains=4,thin=1,control = list(adapt_delta = 0.9,max_treedepth=15))\n\nfit &lt;- stan(file=\"ACN002.stan\",\n                   data=datastruct,\n                   pars=parameters,\n                   iter=2000,\n                   warmup=1000,\n                   init=init,\n                   chains=4,thin=1,control = list(max_treedepth=12))\n\n\nBelow code preapering data to fit the model in supercomputer:\n\n\nCode\nlogP=DS$logP_ACD[!duplicated(DS$ID)]\nnAnalytes=length(unique(DS$ID))\nnObs=length(DS$ID)\nanalyte=DS$ID\nlogkObs=DS$logk\nfi=DS$concentration\nfiplot=seq(0,1,0.1)\nnfiplot=length(fiplot)\nrun_estimation=1\n\nstan_rdump(c(\"logP\",\n             \"nAnalytes\", \n             \"nObs\",\n             \"idxmissing\", \n             \"analyte\", \n             \"logkObs\", \n             \"fi\",\n             \"rawlambdai\",\n             \"nfiplot\",\n             \"fiplot\",\n             \"run_estimation\"),\n           file=\"4_model_2/model.data.R\")\n\n\nWarning in stan_rdump(c(\"logP\", \"nAnalytes\", \"nObs\", \"idxmissing\", \"analyte\", :\nobjects not found: rawlambdai\n\n\nCode\nfor(i in 1:10){\n  logkwHat  = sort(c(rnorm(1,2,0.2),rnorm(1,2,0.2)+max(0,rnorm(1,2,0.5))))\n  logkaHat  = sort(c(rnorm(1,-4,0.2),rnorm(1,-4,0.2)+max(0,rnorm(1,2,0.5))))\n  logS2AHat = rnorm(2,log(2),0.2)\n  omega1= c(1,1,0.1)*exp(rnorm(3,0,0.2))\n  rho1 = diag(1,3,3)\n  omega2= c(1,1,0.1)*exp(rnorm(3,0,0.2))\n  rho2 = diag(1,3,3)\n  beta = c(0.7,0.7,0.5,0.5,0,0)*exp(rnorm(6,0,0.2))\n  param1 = Parameters_basic_fit[,3:5]*0.9\n  param2 = Parameters_basic_fit[,3:5]*1.1\n  sigma  = rlnorm(1,log(0.1),0.2)\n  \n  stan_rdump(c(\"logkwHat\",\"logkaHat\",\"logS2AHat\",\"beta\",\"rho1\",\"rho2\",\"omega1\",\"omega2\",\"param1\",\"param2\",\"sigma\"),\n             file=paste(\"4_model_2/model_\", i, \".init.R\", sep=\"\"))\n}"
  },
  {
    "objectID": "model_2.html#summary-of-model-parameters",
    "href": "model_2.html#summary-of-model-parameters",
    "title": "",
    "section": "Summary of model parameters",
    "text": "Summary of model parameters\nCode for print summary of parameters from supercomputer:\n\n\nCode\nfit &lt;- cmdstanr::as_cmdstan_fit(c('4_model_2/output_1.csv',\n                                  '4_model_2/output_2.csv',\n                                  '4_model_2/output_3.csv',\n                                  '4_model_2/output_4.csv',\n                                  '4_model_2/output_5.csv',\n                                  '4_model_2/output_6.csv',\n                                  '4_model_2/output_7.csv',\n                                  '4_model_2/output_8.csv',\n                                  '4_model_2/output_9.csv',\n                                  '4_model_2/output_10.csv'))\n\nfit$print(c(\"logkwHat\",\"logkaHat\",\"logS2AHat\",\"beta\",\"rho1\",\"rho2\",\"omega1\",\"omega2\",\"param1\",\"param2\",\"sigma\"), max_rows = 26)\n\n\nCode for print summary of parameters from computer:\n\n\nCode\nload(\"4_model_2/Fit.Rsave\")\nload(\"4_model_2/Fit_sample.Rsave\")\n\nprint(fit,pars=c(\"logkwHat\",\"logkaHat\",\"logS2AHat\",\"beta\",\"rho1\",\"rho2\",\"omega1\",\"omega2\",\"sigma\"))\n\n\nInference for Stan model: ACN0021_10_09.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n              mean se_mean   sd  2.5%   25%   50%   75% 97.5% n_eff Rhat\nlogkwHat[1]   1.13       0 0.14  0.86  1.03  1.13  1.21  1.40   962 1.00\nlogkwHat[2]   2.57       0 0.12  2.33  2.49  2.57  2.65  2.81  1971 1.00\nlogkaHat[1]  -2.95       0 0.11 -3.18 -3.02 -2.95 -2.87 -2.73   616 1.00\nlogkaHat[2]  -1.21       0 0.03 -1.27 -1.23 -1.21 -1.19 -1.15  2136 1.00\nlogS2AHat[1]  0.46       0 0.03  0.41  0.44  0.46  0.48  0.51   590 1.00\nlogS2AHat[2]  0.61       0 0.02  0.58  0.60  0.61  0.62  0.64  1534 1.00\nbeta[1]       0.87       0 0.05  0.78  0.83  0.87  0.90  0.96   783 1.01\nbeta[2]       0.85       0 0.04  0.76  0.82  0.85  0.87  0.93  1102 1.00\nbeta[3]       0.25       0 0.03  0.18  0.23  0.25  0.27  0.32   610 1.00\nbeta[4]       0.20       0 0.01  0.18  0.20  0.20  0.21  0.22  2352 1.00\nbeta[5]      -0.01       0 0.01 -0.03 -0.02 -0.01 -0.01  0.00   615 1.00\nbeta[6]      -0.05       0 0.01 -0.06 -0.05 -0.05 -0.04 -0.04  1031 1.00\nrho1[1,1]     1.00     NaN 0.00  1.00  1.00  1.00  1.00  1.00   NaN  NaN\nrho1[1,2]     0.44       0 0.05  0.34  0.41  0.44  0.48  0.54   432 1.03\nrho1[1,3]     0.43       0 0.05  0.33  0.39  0.43  0.46  0.52   594 1.01\nrho1[2,1]     0.44       0 0.05  0.34  0.41  0.44  0.48  0.54   432 1.03\nrho1[2,2]     1.00       0 0.00  1.00  1.00  1.00  1.00  1.00  3366 1.00\nrho1[2,3]     0.62       0 0.04  0.53  0.59  0.62  0.64  0.69   519 1.02\nrho1[3,1]     0.43       0 0.05  0.33  0.39  0.43  0.46  0.52   594 1.01\nrho1[3,2]     0.62       0 0.04  0.53  0.59  0.62  0.64  0.69   519 1.02\nrho1[3,3]     1.00       0 0.00  1.00  1.00  1.00  1.00  1.00   159 1.00\nrho2[1,1]     1.00     NaN 0.00  1.00  1.00  1.00  1.00  1.00   NaN  NaN\nrho2[1,2]     0.32       0 0.05  0.23  0.29  0.32  0.35  0.41  1313 1.00\nrho2[1,3]     0.39       0 0.05  0.29  0.35  0.39  0.42  0.48   786 1.00\nrho2[2,1]     0.32       0 0.05  0.23  0.29  0.32  0.35  0.41  1313 1.00\nrho2[2,2]     1.00       0 0.00  1.00  1.00  1.00  1.00  1.00  3333 1.00\nrho2[2,3]    -0.21       0 0.05 -0.31 -0.24 -0.21 -0.17 -0.10   844 1.01\nrho2[3,1]     0.39       0 0.05  0.29  0.35  0.39  0.42  0.48   786 1.00\nrho2[3,2]    -0.21       0 0.05 -0.31 -0.24 -0.21 -0.17 -0.10   844 1.01\nrho2[3,3]     1.00       0 0.00  1.00  1.00  1.00  1.00  1.00  2528 1.00\nomega1[1]     1.31       0 0.07  1.17  1.26  1.30  1.35  1.46   490 1.00\nomega1[2]     1.01       0 0.05  0.92  0.98  1.01  1.04  1.11   475 1.01\nomega1[3]     0.23       0 0.01  0.20  0.22  0.23  0.24  0.25   479 1.01\nomega2[1]     1.50       0 0.07  1.37  1.45  1.50  1.54  1.64   676 1.00\nomega2[2]     0.36       0 0.02  0.32  0.34  0.36  0.37  0.39   678 1.01\nomega2[3]     0.18       0 0.01  0.17  0.18  0.18  0.19  0.20   838 1.00\nsigma         0.03       0 0.00  0.03  0.03  0.03  0.03  0.03   745 1.01\n\nSamples were drawn using NUTS(diag_e) at Mon Nov 09 13:55:42 2020.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1)."
  },
  {
    "objectID": "model_2.html#goodness-of-fit",
    "href": "model_2.html#goodness-of-fit",
    "title": "",
    "section": "Goodness of fit",
    "text": "Goodness of fit\n\n\nCode\nlibrary(metRology) # function rt.scaled\n\nlogkPred &lt;-array(rep(5097*4000),dim=c(4000,5097))\nfor(j in 1:nObs){\n  for(k in 1:4000){\n    logkPred[k,j]       = rt.scaled(1,7,fit_sample$logkHatPred[k,j], fit_sample$sigma[k])\n  }\n}\n\npar(mfrow=c(1,2))\nplot(apply(fit_sample$logkCond,2,mean),DS$logk,cex.lab=1.2,xlim=c(-4,6),ylim=c(-3,3),pch=20,col=\"blue\",ylab=expression(\"Log k\"[Obs]),xlab=expression(\"Log k\"[Pred]))\nlines(seq(-4,6,by=0.1),seq(-4,6,by=0.1),lwd=2)\nplot(apply(logkPred,2,mean),DS$logk,cex.lab=1.2,xlim=c(-4,6),ylim=c(-3,3),pch=20,col=\"blue\",ylab=expression(\"Log k\"[Obs]),xlab=expression(\"Log k\"[Pred]))\nlines(seq(-4,6,by=0.1),seq(-4,6,by=0.1),lwd=2)\n\n\n\n\n\n\nWAIC\n\n\nCode\nlibrary(loo)\nwaic(extract_log_lik(fit)) # to samo co: waic(fit_sample$log_lik)\n\n\nWarning: \n2211 (43.4%) p_waic estimates greater than 0.4. We recommend trying loo instead.\n\n\n\nComputed from 4000 by 5097 log-likelihood matrix\n\n          Estimate    SE\nelpd_waic   7660.0 219.5\np_waic      3635.8 203.4\nwaic      -15320.1 438.9\n\n2211 (43.4%) p_waic estimates greater than 0.4. We recommend trying loo instead. \n\n\nCode\nloo(extract_log_lik(fit))\n\n\nWarning: Relative effective sample sizes ('r_eff' argument) not specified.\nFor models fit with MCMC, the reported PSIS effective sample sizes and \nMCSE estimates will be over-optimistic.\n\n\nWarning: Some Pareto k diagnostic values are too high. See help('pareto-k-diagnostic') for details.\n\n\n\nComputed from 4000 by 5097 log-likelihood matrix\n\n         Estimate    SE\nelpd_loo   7325.4 122.8\np_loo      3970.5  95.5\nlooic    -14650.8 245.7\n------\nMonte Carlo SE of elpd_loo is NA.\n\nPareto k diagnostic values:\n                         Count Pct.    Min. n_eff\n(-Inf, 0.5]   (good)     2863  56.2%   77        \n (0.5, 0.7]   (ok)        987  19.4%   50        \n   (0.7, 1]   (bad)       917  18.0%   12        \n   (1, Inf)   (very bad)  330   6.5%   2         \nSee help('pareto-k-diagnostic') for details."
  },
  {
    "objectID": "model_2.html#predictions",
    "href": "model_2.html#predictions",
    "title": "",
    "section": "Predictions",
    "text": "Predictions\nIndividual predictions\n\n\nCode\nlibrary(ggpubr)\n\nnazwy &lt;- c(\"Caffeine\",\"Chlorpropamide\",\"Doxepin hydrochloride\",\"Perphenazine\",\n  \"Pindolol\",\"Phenylbutazone\",\"Procainamide hydrochloride\",\"Retinoic acid\",\n  \"Sulfaphenazole\",\"Tolbutamide\",\"Ketoprofen\",\"Indomethacin\")\nl_nazwy &lt;- which(DS_names$Analyte[!duplicated(DS_names$ID)] %in% nazwy)\n\nplots &lt;- list()\nfor(i in 1:nAnalytes){\n  l &lt;- apply(drop(fit_sample$logkPlotACond[,i,]), MARGIN = 2, FUN = quantile, probs = c(.025,.5,.975))\n  logk_prct &lt;- as.data.frame(cbind(rep(i,11),fiplot,t(l)))\n  colnames(logk_prct)&lt;-c(\"ID\",\"concentration\",\"low\",\"median\",\"high\")\n  plots[[i]] &lt;- ggplot()+ xlim(0,1) +\n    geom_point(data=subset(DS, ID == i), aes(x = concentration, y = logk), col=\"blue\") +\n    geom_line(data=subset(logk_prct, ID == i), aes(x = fiplot, y = median), col=\"blue\") +\n    geom_ribbon(data=subset(logk_prct, ID == i), aes(x = fiplot, \n                                                     ymin = low, \n                                                     ymax = high), alpha = 0.25, fill=\"blue\")+\n    coord_cartesian(ylim = c(-3, 4)) + \n    labs(title = paste(DS$Names[which(DS$ID==i)]),\n         x = NULL,\n         y = NULL) +\n    theme(text = element_text(size = 9), axis.text = element_text(size = 9),\n          legend.position = \"none\", strip.text = element_text(size = 6)) \n}\nfigure1 &lt;- ggarrange(plotlist = plots[l_nazwy], nrow=3,ncol = 4)\nannotate_figure(figure1,\n                bottom = text_grob(expression(varphi)),\n                left = text_grob(\"log k\", rot = 90))\n\n\n\n\n\nPopulation predictions\n\n\nCode\nhplc &lt;- function(fi,logkw,logka,logS2A){\n  S1 = (logkw - logka)*(1+10^logS2A)\n  logk = logkw - S1 * fi / (1 + 10^logS2A * fi)\n  return(logk)\n}\n\nlogkHatPlotAPred &lt;-array(rep(0,11*1026*8000),dim=c(8000,1026,11))\nlogkPlotAPred &lt;-array(rep(0,11*1026*8000),dim=c(8000,1026,11))\n\nfor(j in 1:nAnalytes){\n  for(z in 1:nfiplot){\n    for(k in 1:8000){\n      logkHatPlotAPred[k,j,z]   = hplc(fiplot[z], fit_sample$logkwPred[k,j],\n                                   fit_sample$logkaPred[k,j], fit_sample$logS2APred[k,j])\n      logkPlotAPred[k,j,z]      = rt.scaled(1,7,logkHatPlotAPred[k,j,z], fit_sample$sigma[k])\n    }\n  }\n}\n\nplots &lt;- list()\nfor(i in 1:nAnalytes){\n  l &lt;- apply(drop(logkPlotAPred[,i,]), MARGIN = 2, FUN = quantile, probs = c(.025,.5,.975))\n  logk_prct &lt;- as.data.frame(cbind(rep(i,11),fiplot,t(l)))\n  colnames(logk_prct)&lt;-c(\"ID\",\"concentration\",\"low\",\"median\",\"high\")\n  plots[[i]] &lt;- ggplot()+ xlim(0,1) +\n    geom_point(data=subset(DS, ID == i), aes(x = concentration, y = logk), col=\"blue\") +\n    geom_line(data=subset(logk_prct, ID == i), aes(x = fiplot, y = median), col=\"red\") +\n    geom_ribbon(data=subset(logk_prct, ID == i), aes(x = fiplot, \n                                                     ymin = low, \n                                                     ymax = high), alpha = 0.25, fill=\"red\")+\n    coord_cartesian(ylim = c(-3, 4)) + \n    labs(title = paste(DS$Names[which(DS$ID==i)]),\n         x = NULL,\n         y = NULL) +\n    theme(text = element_text(size = 9), axis.text = element_text(size = 9),\n          legend.position = \"none\", strip.text = element_text(size = 6)) \n}\nfigure1 &lt;- ggarrange(plotlist = plots[l_nazwy], nrow=3,ncol = 4)\nannotate_figure(figure1,\n                bottom = text_grob(expression(varphi)),\n                left = text_grob(\"log k\", rot = 90))"
  }
]